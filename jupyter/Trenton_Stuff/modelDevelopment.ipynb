{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d16ee7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary modules from repository\n",
    "from model.data.pipeline import utils as ut\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3031ba1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#dataframe of all monthly data\n",
    "df = ut.load_sql_as_df('SELECT * From MonthlyDataModel;')\n",
    "\n",
    "#dataframe of month averages to fill in bad values\n",
    "monthAvg = ut.load_sql_as_df('SELECT * From MonthlyAverages;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Getting features and choosing labels. Fill NaN spots with NaN text to manipulate them\n",
    "labels = df[\"state\"]\n",
    "#['region', 'latitude', 'longitude', 'elevation', 'region'] are all dropped automatically\n",
    "df = df.fillna('NaN')\n",
    "\n",
    "# Changing columns in to months to help compare\n",
    "featSer = df[\"month\"].to_numpy()\n",
    "prcpIntM = monthAvg[\"prcpInt\"].to_numpy()\n",
    "prcpFreqM = monthAvg[\"prcpFreq\"].to_numpy()\n",
    "temp_max_normalM = monthAvg[\"temp_max_normal\"].to_numpy()\n",
    "temp_min_normalM = monthAvg[\"temp_min_normal\"].to_numpy()\n",
    "snow_depthM = monthAvg[\"snowInt\"].to_numpy()\n",
    "snow_daysM = monthAvg[\"snowFreq\"].to_numpy()\n",
    "cloudsM = monthAvg[\"clouds\"].to_numpy()\n",
    "dewM = monthAvg[\"dew_point\"].to_numpy()\n",
    "heatM = monthAvg[\"heat_index\"].to_numpy()\n",
    "pressureM = monthAvg[\"pressure\"].to_numpy()\n",
    "windM = monthAvg[\"wind_speed\"].to_numpy()\n",
    "windCalmM = monthAvg[\"wind_calm_percentage\"].to_numpy()\n",
    "\n",
    "prcp_normRay = df[\"prcp_normal\"].to_numpy()\n",
    "prcp_days_tRay = df[\"prcp_days_t\"].to_numpy()\n",
    "temp_max_normalRay = df[\"temp_max_normal\"].to_numpy()\n",
    "temp_min_normalRay = df[\"temp_min_normal\"].to_numpy()\n",
    "snow_depthRay = df[\"snow_depth_days\"].to_numpy()\n",
    "snow_daysRay = df[\"snow_days_t\"].to_numpy()\n",
    "cloudsRay = df[\"clouds\"].to_numpy()\n",
    "dewRay = df[\"dew_point\"].to_numpy()\n",
    "heatRay = df[\"heat_index\"].to_numpy()\n",
    "pressureRay = df[\"pressure\"].to_numpy()\n",
    "windRay = df[\"wind_speed\"].to_numpy()\n",
    "windCalmRay = df[\"wind_calm_percentage\"].to_numpy()\n",
    "\n",
    "#replacing bad values\n",
    "for i in range(len(featSer)):\n",
    "    if prcp_normRay[i] == 'NaN' or prcp_normRay[i] == -9999 or prcp_normRay[i] == -8888 or prcp_normRay[i] == -7777 or prcp_normRay[i] == -6666 or prcp_normRay[i] == -5555:\n",
    "        prcp_normRay[i] = prcpIntM[featSer[i] - 1]\n",
    "    if prcp_days_tRay[i] == 'NaN' or prcp_days_tRay[i] == -9999 or prcp_days_tRay[i] == -8888 or prcp_days_tRay[\n",
    "        i] == -7777 or prcp_days_tRay[i] == -6666 or prcp_days_tRay[i] == -5555:\n",
    "        prcp_days_tRay[i] = prcpFreqM[featSer[i] - 1]\n",
    "    if temp_max_normalRay[i] == 'NaN' or temp_max_normalRay[i] == -9999 or temp_max_normalRay[i] == -8888 or temp_max_normalRay[i] == -7777 or temp_max_normalRay[i] == -6666 or temp_max_normalRay[i] == -5555:\n",
    "        temp_max_normalRay[i] = temp_max_normalM[featSer[i] - 1]\n",
    "    if temp_min_normalRay[i] == 'NaN' or temp_min_normalRay[i] == -9999 or temp_min_normalRay[i] == -8888 or temp_min_normalRay[i] == -7777 or temp_min_normalRay[i] == -6666 or temp_min_normalRay[i] == -5555:\n",
    "        temp_min_normalRay[i] = temp_min_normalM[featSer[i] - 1]\n",
    "    if snow_depthRay[i] == 'NaN' or snow_depthRay[i] == -9999 or snow_depthRay[i] == -8888 or snow_depthRay[i] == -7777 or snow_depthRay[i] == -6666 or snow_depthRay[i] == -5555:\n",
    "        snow_depthRay[i] = snow_depthM[featSer[i] - 1]\n",
    "    if snow_daysRay[i] == 'NaN' or snow_daysRay[i] == -9999 or snow_daysRay[i] == -8888 or snow_daysRay[i] == -7777 or snow_daysRay[i] ==-6666 or snow_daysRay[i] == -5555:\n",
    "        snow_daysRay[i] = snow_daysM[featSer[i] - 1]\n",
    "    if cloudsRay[i] == 'NaN' or cloudsRay[i] == -9999 or cloudsRay[i] == -8888 or cloudsRay[i] == -7777 or cloudsRay[i] == -6666 or cloudsRay[i] == -5555:\n",
    "        cloudsRay[i] = cloudsM[featSer[i] - 1]\n",
    "    if dewRay[i] == 'NaN' or dewRay[i] == -9999 or dewRay[i] == -8888 or dewRay[i] == -7777 or dewRay[i] == -6666 or dewRay[i] == -5555:\n",
    "        dewRay[i] = dewM[featSer[i] - 1]\n",
    "    if heatRay[i] == 'NaN' or heatRay[i] == -9999 or heatRay[i] == -8888 or heatRay[i] == -7777 or heatRay[i] == -6666 or heatRay[i] == -5555:\n",
    "        heatRay[i] = heatM[featSer[i] - 1]\n",
    "    if pressureRay[i] == 'NaN' or pressureRay[i] == -9999 or pressureRay[i] == -8888 or pressureRay[i] == -7777 or pressureRay[i] == -6666 or pressureRay[i] == -5555:\n",
    "        pressureRay[i] = pressureM[featSer[i] - 1]\n",
    "    if windRay[i] == 'NaN' or windRay[i] == -9999 or windRay[i] == -8888 or windRay[i] == -7777 or windRay[i] == -6666 or windRay[i] == -5555:\n",
    "        windRay[i] = windM[featSer[i] - 1]\n",
    "    if windCalmRay[i] == 'NaN' or windCalmRay[i] == -9999 or windCalmRay[i] == -8888 or windCalmRay[i] == -7777 or windCalmRay[i] == -6666 or windCalmRay[i] == -5555:\n",
    "        windCalmRay[i] = windCalmM[featSer[i] - 1]\n",
    "\n",
    "df1 = df.copy()\n",
    "# Recreating filled dataset\n",
    "df = pd.DataFrame({'state': labels, 'prcp_normRay': prcp_normRay, 'prcp_days_tRay': prcp_days_tRay,\n",
    "                   \"temp_max_normalRay\": temp_max_normalRay, \"temp_min_normalRay\": temp_min_normalRay,\n",
    "                   \"snow_depthRay\": snow_depthRay, \"snow_daysRay\": snow_daysRay, \"cloudsRay\": cloudsRay,\n",
    "                   \"dewRay\": dewRay, \"heatRay\": heatRay, \"pressureRay\": pressureRay, \"windRay\": windRay,\n",
    "                   \"windCalmRay\": windCalmRay})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       state prcp_normRay prcp_days_tRay temp_max_normalRay  \\\n0         AL          5.3           69.0          41.924644   \n1         AL         5.07           65.0          45.985372   \n2         AL          5.8           62.0          54.495133   \n3         AL         3.77           48.0          64.407005   \n4         AL         3.82           48.0          73.406937   \n...      ...          ...            ...                ...   \n117031    NE         3.22      25.909684               85.4   \n117032    NE         3.04      46.810539               77.8   \n117033    NE         2.04      47.409751               65.2   \n117034    NE         1.41      49.541899               49.7   \n117035    NE         0.93      50.036534               36.9   \n\n       temp_min_normalRay snow_depthRay snow_daysRay  cloudsRay     dewRay  \\\n0               21.303576           0.0          0.0  55.667977  26.341895   \n1               24.106816           0.0          0.0  55.013862  28.228661   \n2               31.252366    -309.95931  -297.336583  52.051446  33.052022   \n3               39.586609           0.0          0.0  49.932187   39.67777   \n4                48.77541           0.0          0.0  48.941521  48.669454   \n...                   ...           ...          ...        ...        ...   \n117031               62.7     -6.026158   -32.307496  40.020323  59.955251   \n117032               53.6   -156.429374  -337.711363  41.015647  53.890063   \n117033               40.6   -553.695795  -656.829311  45.018233   44.25134   \n117034               28.0   -244.419299  -363.569282   51.45818  35.445112   \n117035               17.1   -238.601821  -291.094614  55.725457   28.84527   \n\n          heatRay  pressureRay   windRay windCalmRay longitude_bin  \n0       35.417982  1018.967064  8.593669    14.68457             3  \n1       38.559721  1018.084567  8.813964   13.644477             3  \n2       45.700434   1016.38444  9.329369   11.746978             3  \n3       54.337107  1014.836497  9.386922    11.09783             3  \n4         63.3096   1014.35943  8.659783   12.057727             3  \n...           ...          ...       ...         ...           ...  \n117031  74.535821   1015.39399  7.050787   16.593875             3  \n117032  67.271141  1015.676289  7.402396   16.429875             3  \n117033  56.376711   1016.88648  7.768246   16.520839             3  \n117034  45.895488  1017.744118  8.266765   15.842452             3  \n117035  37.656348  1018.840951  8.419217   15.283866             3  \n\n[117036 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>prcp_normRay</th>\n      <th>prcp_days_tRay</th>\n      <th>temp_max_normalRay</th>\n      <th>temp_min_normalRay</th>\n      <th>snow_depthRay</th>\n      <th>snow_daysRay</th>\n      <th>cloudsRay</th>\n      <th>dewRay</th>\n      <th>heatRay</th>\n      <th>pressureRay</th>\n      <th>windRay</th>\n      <th>windCalmRay</th>\n      <th>longitude_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AL</td>\n      <td>5.3</td>\n      <td>69.0</td>\n      <td>41.924644</td>\n      <td>21.303576</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55.667977</td>\n      <td>26.341895</td>\n      <td>35.417982</td>\n      <td>1018.967064</td>\n      <td>8.593669</td>\n      <td>14.68457</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AL</td>\n      <td>5.07</td>\n      <td>65.0</td>\n      <td>45.985372</td>\n      <td>24.106816</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55.013862</td>\n      <td>28.228661</td>\n      <td>38.559721</td>\n      <td>1018.084567</td>\n      <td>8.813964</td>\n      <td>13.644477</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AL</td>\n      <td>5.8</td>\n      <td>62.0</td>\n      <td>54.495133</td>\n      <td>31.252366</td>\n      <td>-309.95931</td>\n      <td>-297.336583</td>\n      <td>52.051446</td>\n      <td>33.052022</td>\n      <td>45.700434</td>\n      <td>1016.38444</td>\n      <td>9.329369</td>\n      <td>11.746978</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AL</td>\n      <td>3.77</td>\n      <td>48.0</td>\n      <td>64.407005</td>\n      <td>39.586609</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>49.932187</td>\n      <td>39.67777</td>\n      <td>54.337107</td>\n      <td>1014.836497</td>\n      <td>9.386922</td>\n      <td>11.09783</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AL</td>\n      <td>3.82</td>\n      <td>48.0</td>\n      <td>73.406937</td>\n      <td>48.77541</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48.941521</td>\n      <td>48.669454</td>\n      <td>63.3096</td>\n      <td>1014.35943</td>\n      <td>8.659783</td>\n      <td>12.057727</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>117031</th>\n      <td>NE</td>\n      <td>3.22</td>\n      <td>25.909684</td>\n      <td>85.4</td>\n      <td>62.7</td>\n      <td>-6.026158</td>\n      <td>-32.307496</td>\n      <td>40.020323</td>\n      <td>59.955251</td>\n      <td>74.535821</td>\n      <td>1015.39399</td>\n      <td>7.050787</td>\n      <td>16.593875</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>117032</th>\n      <td>NE</td>\n      <td>3.04</td>\n      <td>46.810539</td>\n      <td>77.8</td>\n      <td>53.6</td>\n      <td>-156.429374</td>\n      <td>-337.711363</td>\n      <td>41.015647</td>\n      <td>53.890063</td>\n      <td>67.271141</td>\n      <td>1015.676289</td>\n      <td>7.402396</td>\n      <td>16.429875</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>117033</th>\n      <td>NE</td>\n      <td>2.04</td>\n      <td>47.409751</td>\n      <td>65.2</td>\n      <td>40.6</td>\n      <td>-553.695795</td>\n      <td>-656.829311</td>\n      <td>45.018233</td>\n      <td>44.25134</td>\n      <td>56.376711</td>\n      <td>1016.88648</td>\n      <td>7.768246</td>\n      <td>16.520839</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>117034</th>\n      <td>NE</td>\n      <td>1.41</td>\n      <td>49.541899</td>\n      <td>49.7</td>\n      <td>28.0</td>\n      <td>-244.419299</td>\n      <td>-363.569282</td>\n      <td>51.45818</td>\n      <td>35.445112</td>\n      <td>45.895488</td>\n      <td>1017.744118</td>\n      <td>8.266765</td>\n      <td>15.842452</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>117035</th>\n      <td>NE</td>\n      <td>0.93</td>\n      <td>50.036534</td>\n      <td>36.9</td>\n      <td>17.1</td>\n      <td>-238.601821</td>\n      <td>-291.094614</td>\n      <td>55.725457</td>\n      <td>28.84527</td>\n      <td>37.656348</td>\n      <td>1018.840951</td>\n      <td>8.419217</td>\n      <td>15.283866</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>117036 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adds another column showing which bin every row falls into. The bins are based on the temp_max_normalRay column\n",
    "df['longitude_bin'] = pd.cut(df1['longitude'],\n",
    "                             bins=[-400, -125, -100, -75, np.inf],\n",
    "                             labels=[1, 2, 3, 4])\n",
    "df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2,\n",
    "                               random_state=42)  #n_splits is training date, test_size is target\n",
    "\n",
    "for train_index, test_index in split.split(df, df[\"longitude_bin\"]):  #shows it is an iterateable object\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "\n",
    "#SELECT COUNT(*) GROUP BY region;\n",
    "#     check if we need strat_sampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "lab_train = strat_train_set['state']\n",
    "feat_train = strat_train_set.drop(['state', 'longitude_bin'], axis=1)\n",
    "lab_test = strat_test_set['state']\n",
    "feat_test = strat_test_set.drop(['state', 'longitude_bin'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'from sklearn.model_selection import train_test_split\\n\\nfeat_train, feat_test, lab_train, lab_test = train_test_split(featPrepped, labels, random_state=42)\\n# stratify by city for separating training and testing. stratified sampling'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler = StandardScaler()  # makes 0 the average\n",
    "feat_train = scaler.fit_transform(feat_train)\n",
    "feat_train = scaler2.fit_transform(feat_train)\n",
    "feat_train += 1\n",
    "\n",
    "\"\"\"from sklearn.model_selection import train_test_split\n",
    "\n",
    "feat_train, feat_test, lab_train, lab_test = train_test_split(featPrepped, labels, random_state=42)\n",
    "# stratify by city for separating training and testing. stratified sampling\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.70220058, 1.18894685, 1.80140187, ..., 1.58060448, 1.14415524,\n        1.18075128],\n       [1.75595238, 1.29019608, 1.73831776, ..., 1.59488907, 1.15967809,\n        1.16184733],\n       [1.72249278, 1.16470588, 1.56619938, ..., 1.73937505, 1.16314962,\n        1.18346311],\n       ...,\n       [1.71843434, 1.12941176, 1.62928349, ..., 1.76871272, 1.15426152,\n        1.20579598],\n       [1.73097042, 1.18431373, 1.66199377, ..., 1.78647894, 1.06086056,\n        1.54195104],\n       [1.74540043, 1.21011523, 1.60124611, ..., 1.67343264, 1.17475444,\n        1.15761409]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef48f30a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afaa8d6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier()\n",
    "ex = ExtraTreesClassifier()\n",
    "bnb = BernoulliNB(binarize=0.0, class_prior=None, fit_prior=True)\n",
    "cnb = ComplementNB(class_prior=None, fit_prior=True, norm=False)   #negative values passed?\n",
    "mnb = MultinomialNB(class_prior=None, fit_prior=True)   #negative values passed?\n",
    "gnb = GaussianNB(priors=None)\n",
    "rn = RadiusNeighborsClassifier() # no neighbors found\n",
    "lr = LogisticRegression()\n",
    "rc = RidgeClassifier()\n",
    "svc = SVC()\n",
    "lsvc = LinearSVC()\n",
    "nu = NuSVC()\n",
    "mplN = MLPClassifier(batch_size='auto', warm_start=True, max_iter=400)\n",
    "mplS = MLPClassifier(batch_size='auto', warm_start=True, solver='sgd', max_iter=400, early_stopping=True)\n",
    "mplA = MLPClassifier(batch_size='auto', warm_start=True, solver='adam', max_iter=400, early_stopping=True)\n",
    "nc = NearestCentroid()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "kn = KNeighborsClassifier()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "gpc = GaussianProcessClassifier()\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "ensemble_clf = [rf, ex, ex, bnb, cnb, mnb, gnb, rn, lr, rc, svc, lsvc, nu, mplN,mplS,mplA, nc, qda, kn, lda, gpc, sgd]\n",
    "\n",
    "rfParam = {\"max_depth\": range(5, 30, 5), \"min_samples_leaf\": range(1, 30, 10),\n",
    "           \"n_estimators\": range(1, 15, 4),\n",
    "           'bootstrap': [True,False],\n",
    "           'max_features': [1, 7, 'auto', 'sqrt'],\n",
    "           'warm_start': [True,False]}\n",
    "exParamOob = {\n",
    "    'n_estimators': range(1,15, 4),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": range(1,30, 5),\n",
    "    'min_samples_split': range(2, 15, 4),\n",
    "    'min_samples_leaf': range(1, 25, 6),\n",
    "    'oob_score': [True, False],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', range(50, 200, 75)],\n",
    "    'bootstrap': [True],\n",
    "    'warm_start': [True, False],\n",
    "}\n",
    "exParam = {\n",
    "    'n_estimators': range(1,15, 4),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": range(1,30, 5),\n",
    "    'min_samples_split': range(2, 15, 4),\n",
    "    'min_samples_leaf': range(1, 25, 6),\n",
    "    'max_features': ['auto', 'sqrt', 'log2', range(50, 200, 75)],\n",
    "    'bootstrap': [True,False],\n",
    "    'warm_start': [True, False],\n",
    "}\n",
    "bnbParam = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "            }\n",
    "cnbParam = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0, ],\n",
    "            }\n",
    "mnbParam = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0, ],\n",
    "            }\n",
    "gnbParam = {\n",
    "    'var_smoothing': np.logspace(0, -9, num=15)\n",
    "}\n",
    "rnParam = {'radius': np.arange(0.8, 1.5, 0.4),\n",
    "           'weights': ['uniform', 'distance']}\n",
    "lrParam = {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'penalty': ['l2','none'],\n",
    "           'C': [10, 0.1, 0.001]}\n",
    "rcParam = {'alpha': [0.1, 0.5, 1.0]}\n",
    "svcParam = {'C': [0.01, 1, 3 'auto'],\n",
    "            'gamma': [0.1, 1.0, 2],\n",
    "            'kernel': ['rbf', 'linear', 'sigmoid']\n",
    "            }\n",
    "lsvcParam = {\n",
    "    'C': [0.1, 0.5, 1.0],\n",
    "}\n",
    "nuParam = {\n",
    "    'nu': [0.1, 1.0],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid', ],\n",
    "    'gamma': ['auto', 'scale']\n",
    "}\n",
    "mplNParam = {\n",
    "    'hidden_layer_sizes': (10,120,10),\n",
    "    'activation': ('identity', 'logistic', 'tanh', 'relu'),\n",
    "    'alpha': (0.000001, 0.00001, 0.0001),\n",
    "    'solver': ('lbfgs', 'sgd', 'adam'),\n",
    "    'shrinking': (True, False),\n",
    "}\n",
    "mplSParam = {\n",
    "    'hidden_layer_sizes': (10,120,10),\n",
    "    'activation': ('identity', 'logistic', 'tanh', 'relu'),\n",
    "    'alpha': (0.000001, 0.00001, 0.0001),\n",
    "    'learning_rate': ('constant', 'invscaling', 'adaptive'),\n",
    "    'momentum': (0.1,0.9,0.1),\n",
    "}\n",
    "mplAParam = {\n",
    "    'hidden_layer_sizes': (10,120,10),\n",
    "    'activation': ('identity', 'logistic', 'tanh', 'relu'),\n",
    "    'alpha': (0.000001, 0.00001, 0.0001),\n",
    "    'beta_1': (0.1,0.9,0.1),\n",
    "    'beta_2': (0.1,0.9,0.1),\n",
    "                   }\n",
    "ncParam = {}\n",
    "qdaParam = {\n",
    "    'reg_param': (0.00001, 0.001, 0.1),\n",
    "    'store_covariance': (True, False),\n",
    "    'tol': (0.0001, 0.01, 0.1),\n",
    "}\n",
    "knParam = {\n",
    "    'n_neighbors': range(1, 30, 10),\n",
    "    'leaf_size': range(1, 40, 15),\n",
    "    'p': (1, 2),\n",
    "    'weights': ('uniform', 'distance'),\n",
    "    'metric': ('minkowski', 'chebyshev', 'euclidean', 'manhattan'),\n",
    "    'algorithm': ('auto', 'brute', 'kd_tree', 'ball_tree')}\n",
    "ldaParam = {'solver': ['svd', 'lsqr', 'eigen'], 'shrinkage': [np.arange(0, 1, 0.2), 'auto'],\n",
    "            'n_components': range(0, 5, 2), 'store_covariance': (True, False)}\n",
    "gpcParam = {}\n",
    "sgdParam = {'loss': ['hinge', 'log', 'modified_huber','squared_hinge', 'perceptron'],\n",
    "            'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "            'alpha': [0.0001, 0.01, 1, 75, 1000],\n",
    "            'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'eta0': [1, 10, 100],\n",
    "            'n_iter': [1, 5, 10]}\n",
    "\n",
    "parameters_list = [rfParam, exParamOob, exParam, bnbParam, cnbParam, gnbParam, rnParam, lrParam, rcParam, svcParam, lsvcParam,\n",
    "                   nuParam, mplNParam, mplSParam, mplAParam, ncParam, qdaParam, knParam, gpcParam, sgdParam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...:   0%|          | 0/2 [06:23<?, ?it/s]]\u001B[A\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 420, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 131, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 227, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 724, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 695, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 1835008 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 420, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 131, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 227, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 724, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 696, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 13107200 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 420, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 131, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 227, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 724, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 696, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 6553600 bytes\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.07291667 0.13802083 0.13020833 0.13020833 0.04947917 0.09375\n",
      " 0.09635417 0.10677083 0.03645833 0.08072917 0.08854167 0.09375\n",
      " 0.07552083 0.14583333 0.15104167 0.1484375  0.08072917 0.13020833\n",
      " 0.1328125  0.13020833 0.0703125  0.11458333 0.11197917 0.11458333\n",
      " 0.0625     0.140625   0.15104167 0.14322917 0.06510417 0.125\n",
      " 0.12760417 0.12760417 0.05729167 0.109375   0.11197917 0.109375\n",
      " 0.0703125  0.1484375  0.15104167 0.14322917 0.0625     0.13541667\n",
      " 0.13020833 0.13020833 0.09114583 0.11458333 0.1015625  0.11458333\n",
      " 0.078125   0.15625    0.15364583 0.1484375  0.0625     0.109375\n",
      " 0.10677083 0.09635417 0.05729167 0.09635417 0.0859375  0.0859375\n",
      " 0.12760417 0.16927083 0.15104167 0.14583333 0.07291667 0.13802083\n",
      " 0.13541667 0.13802083 0.04947917 0.12239583 0.1171875  0.1171875\n",
      " 0.11458333 0.15364583 0.15364583 0.16666667 0.05989583 0.13020833\n",
      " 0.1328125  0.1328125  0.0546875  0.10416667 0.09895833 0.11197917\n",
      " 0.08854167 0.16145833 0.16145833 0.1640625  0.06510417 0.14583333\n",
      " 0.13802083 0.12760417 0.09114583 0.109375   0.109375   0.10416667\n",
      " 0.09114583 0.14322917 0.14583333 0.1484375  0.06510417 0.10677083\n",
      " 0.09895833 0.10677083 0.04427083 0.078125   0.08854167 0.0859375\n",
      " 0.1015625  0.16666667 0.16927083 0.15364583 0.0703125  0.13802083\n",
      " 0.13802083 0.1328125  0.06510417 0.1171875  0.11979167 0.11458333\n",
      " 0.09114583 0.15885417 0.16927083 0.15104167 0.0546875  0.13541667\n",
      " 0.13020833 0.12760417 0.05208333 0.10677083 0.109375   0.10416667\n",
      " 0.07552083 0.15625    0.16145833 0.16145833 0.09114583 0.14322917\n",
      " 0.13020833 0.1328125  0.05989583 0.11458333 0.10677083 0.10416667\n",
      " 0.06770833 0.1484375  0.14322917 0.1484375  0.05989583 0.1015625\n",
      " 0.1015625  0.10677083 0.04947917 0.09635417 0.09895833 0.09375\n",
      " 0.078125   0.15885417 0.15364583 0.15885417 0.06770833 0.13020833\n",
      " 0.13541667 0.1328125  0.08854167 0.11197917 0.12239583 0.11458333\n",
      " 0.08333333 0.15625    0.15885417 0.15885417 0.07291667 0.13020833\n",
      " 0.13541667 0.13020833 0.06510417 0.10677083 0.10416667 0.10677083\n",
      " 0.08854167 0.16927083 0.15364583 0.15625    0.07552083 0.13541667\n",
      " 0.125      0.13020833 0.0625     0.09895833 0.10416667 0.10677083\n",
      " 0.06770833 0.13020833 0.13541667 0.12760417 0.05729167 0.109375\n",
      " 0.109375   0.11458333 0.06510417 0.09635417 0.09895833 0.1015625\n",
      " 0.0859375  0.12760417 0.13802083 0.140625   0.09895833 0.125\n",
      " 0.11979167 0.13020833 0.09375    0.1328125  0.13020833 0.1328125\n",
      " 0.08333333 0.171875   0.16927083 0.17447917 0.08854167 0.14322917\n",
      " 0.14583333 0.14322917 0.0859375  0.125      0.13020833 0.140625\n",
      " 0.0859375  0.171875   0.16666667 0.1640625  0.09635417 0.14322917\n",
      " 0.140625   0.140625   0.078125   0.12760417 0.12239583 0.1328125\n",
      " 0.1171875  0.15364583 0.1484375  0.15625    0.06510417 0.125\n",
      " 0.12239583 0.12239583 0.0625     0.09895833 0.10416667 0.09895833\n",
      " 0.13020833 0.15364583 0.15104167 0.15104167 0.08854167 0.125\n",
      " 0.13020833 0.1328125  0.0859375  0.1328125  0.1328125  0.1328125\n",
      " 0.11458333 0.18489583 0.171875   0.17447917 0.09895833 0.14583333\n",
      " 0.13802083 0.13802083 0.0625     0.14322917 0.13020833 0.125\n",
      " 0.11458333 0.18489583 0.17708333 0.17447917 0.09635417 0.14322917\n",
      " 0.140625   0.14583333 0.078125   0.12760417 0.13541667 0.12760417\n",
      " 0.109375   0.15364583 0.15625    0.14583333 0.0625     0.12760417\n",
      " 0.12239583 0.12239583 0.078125   0.10677083 0.10416667 0.1015625\n",
      " 0.11979167 0.16145833 0.15104167 0.16145833 0.09375    0.1328125\n",
      " 0.13020833 0.12760417 0.0859375  0.13541667 0.13020833 0.1328125\n",
      " 0.11197917 0.171875   0.17447917 0.17447917 0.09635417 0.140625\n",
      " 0.140625   0.13802083 0.08333333 0.13541667 0.12760417 0.13802083\n",
      " 0.11197917 0.16927083 0.171875   0.171875   0.09114583 0.13802083\n",
      " 0.13802083 0.140625   0.08333333 0.1328125  0.12760417 0.13020833\n",
      " 0.10677083 0.15104167 0.1484375  0.15364583 0.05729167 0.12760417\n",
      " 0.11979167 0.12239583 0.046875   0.10416667 0.1015625  0.10677083\n",
      " 0.14322917 0.15885417 0.15625    0.15625    0.08072917 0.13541667\n",
      " 0.12760417 0.12760417 0.09375    0.13541667 0.13541667 0.1328125\n",
      " 0.10677083 0.17447917 0.17447917 0.1796875  0.07291667 0.13541667\n",
      " 0.13802083 0.14322917 0.08333333 0.12760417 0.13020833 0.13020833\n",
      " 0.08854167 0.16666667 0.1796875  0.1640625  0.09375    0.14583333\n",
      " 0.140625   0.13541667 0.07552083 0.13020833 0.12239583 0.1328125\n",
      " 0.15177219 0.1595892  0.15958469 0.1465616  0.14310741 0.17518038\n",
      " 0.13876714 0.17518714 0.17605069 0.16999008 0.15871212 0.16392271\n",
      " 0.1630524  0.17518263 0.12314214 0.1526425  0.17605519 0.17605069\n",
      " 0.16045049 0.1795184  0.17431457 0.14917253 0.17345103 0.17605294\n",
      " 0.1396397  0.13704004 0.17344877 0.13876939 0.13616522 0.1682472\n",
      " 0.13876714 0.13443813 0.13441784 0.15264701 0.16044823 0.15351506\n",
      " 0.17691874 0.16304338 0.13443362 0.14917478 0.15959145 0.16045274\n",
      " 0.192546   0.16392271 0.17258297 0.13617424 0.14482774 0.17952065\n",
      " 0.17257846 0.16046852 0.15785308 0.16305465 0.14310065 0.14396645\n",
      " 0.15526245 0.15785083 0.16217983 0.16046176 0.17172619 0.14743867\n",
      " 0.15352183 0.16739042 0.18819895 0.16998557 0.15177444 0.14483902\n",
      " 0.18994408 0.1569963  0.15612374 0.16045049 0.16133433 0.19601145\n",
      " 0.18906926 0.16565431 0.19514114 0.19167118 0.18299964 0.19340954\n",
      " 0.16738817 0.16652462 0.15525794 0.15959596 0.18820572 0.15526245\n",
      " 0.18820797 0.19948593 0.19168019 0.16566108 0.19687725 0.18906926\n",
      " 0.18386319 0.18994408 0.19167343 0.17085588 0.16912653 0.19601371\n",
      " 0.19428436 0.18472899 0.19167569 0.13617199 0.1855993  0.13964421\n",
      " 0.19774306 0.18473575 0.19253472 0.19427309 0.1873309  0.1379081\n",
      " 0.18994408 0.19168245 0.18473124 0.1370423  0.13444264 0.18906701\n",
      " 0.1864651  0.18473124 0.1855993  0.18299288 0.18559479 0.13357233\n",
      " 0.1873309  0.18559028 0.18385868 0.18560155 0.18386544 0.18733315\n",
      " 0.18647186 0.19254149 0.24256554 0.2497853  0.24169774 0.24083194\n",
      " 0.24083319 0.23967729 0.24891625 0.24285214 0.23909909 0.24314149\n",
      " 0.24343134 0.24285239 0.24487334 0.24083244 0.24314149 0.24400804\n",
      " 0.24343134 0.2474745  0.24776185 0.24458524 0.24458549 0.24747625\n",
      " 0.248919   0.2494937  0.24949495 0.25123005 0.24487459 0.24660795\n",
      " 0.2494947  0.2494967  0.24776185 0.24689655 0.23996614 0.2497853\n",
      " 0.24718615 0.2477631  0.25036025 0.25036    0.24805045 0.24949545\n",
      " 0.25122605 0.24862815 0.25007115 0.31838677 0.31540373 0.31713575\n",
      " 0.3182904  0.3188676  0.3216583  0.31829074 0.31713592 0.3169436\n",
      " 0.3129022  0.31655847 0.31857903 0.31694333 0.31809809 0.31703908\n",
      "        nan        nan        nan 0.37411404 0.37302372]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.1640625  0.68359375 0.66927083 0.68489583 0.10416667 0.33203125\n",
      " 0.32682292 0.33072917 0.08854167 0.1796875  0.1796875  0.16536458\n",
      " 0.171875   0.69661458 0.70833333 0.72135417 0.1640625  0.40625\n",
      " 0.40885417 0.40494792 0.12890625 0.24479167 0.22786458 0.24348958\n",
      " 0.18359375 0.73958333 0.73828125 0.73046875 0.1484375  0.39973958\n",
      " 0.40494792 0.40364583 0.10416667 0.22265625 0.22395833 0.22916667\n",
      " 0.19401042 0.72265625 0.72786458 0.73567708 0.13932292 0.40234375\n",
      " 0.40234375 0.41536458 0.12369792 0.23046875 0.23307292 0.22786458\n",
      " 0.66666667 1.         1.         1.         0.12760417 0.34895833\n",
      " 0.3515625  0.36588542 0.11197917 0.17708333 0.17447917 0.18098958\n",
      " 0.66145833 1.         1.         1.         0.17838542 0.43619792\n",
      " 0.4375     0.44921875 0.12890625 0.23958333 0.23046875 0.24479167\n",
      " 0.67708333 1.         1.         1.         0.15625    0.44401042\n",
      " 0.45182292 0.45052083 0.10546875 0.23307292 0.22135417 0.2265625\n",
      " 0.65104167 1.         1.         1.         0.14192708 0.45833333\n",
      " 0.46223958 0.45703125 0.12369792 0.234375   0.22395833 0.23177083\n",
      " 0.66145833 1.         1.         1.         0.13151042 0.35416667\n",
      " 0.3515625  0.35416667 0.09895833 0.18880208 0.16927083 0.17317708\n",
      " 0.66145833 1.         1.         1.         0.15494792 0.4453125\n",
      " 0.44791667 0.44661458 0.1171875  0.23697917 0.24088542 0.23958333\n",
      " 0.64583333 1.         1.         1.         0.15885417 0.4453125\n",
      " 0.45963542 0.45182292 0.125      0.22005208 0.22395833 0.2265625\n",
      " 0.65885417 1.         1.         1.         0.15104167 0.44140625\n",
      " 0.44661458 0.453125   0.11328125 0.234375   0.23307292 0.22005208\n",
      " 0.640625   1.         1.         1.         0.13020833 0.35416667\n",
      " 0.359375   0.34635417 0.10807292 0.171875   0.16796875 0.1796875\n",
      " 0.63411458 1.         1.         1.         0.17578125 0.44010417\n",
      " 0.45052083 0.44661458 0.12369792 0.23177083 0.23958333 0.24479167\n",
      " 0.69140625 1.         1.         1.         0.15234375 0.4453125\n",
      " 0.44921875 0.45182292 0.11197917 0.23046875 0.22265625 0.23697917\n",
      " 0.64713542 1.         1.         1.         0.16015625 0.44661458\n",
      " 0.44791667 0.4453125  0.109375   0.22265625 0.22395833 0.22786458\n",
      " 0.21223958 0.6171875  0.61067708 0.609375   0.16015625 0.40104167\n",
      " 0.40625    0.40625    0.1484375  0.296875   0.29427083 0.29296875\n",
      " 0.2578125  0.49739583 0.5        0.50651042 0.22526042 0.34895833\n",
      " 0.35026042 0.35546875 0.19140625 0.31380208 0.31380208 0.30859375\n",
      " 0.23177083 0.59895833 0.57942708 0.59765625 0.21744792 0.4609375\n",
      " 0.44661458 0.45703125 0.171875   0.32682292 0.32942708 0.33203125\n",
      " 0.21484375 0.60026042 0.59114583 0.59244792 0.20572917 0.44921875\n",
      " 0.45833333 0.453125   0.16015625 0.33072917 0.33333333 0.33203125\n",
      " 1.         1.         1.         1.         0.19401042 0.49088542\n",
      " 0.48567708 0.4765625  0.13932292 0.29296875 0.30078125 0.28645833\n",
      " 1.         1.         1.         1.         0.25911458 0.45182292\n",
      " 0.45703125 0.45572917 0.19401042 0.3125     0.31901042 0.3203125\n",
      " 1.         1.         1.         1.         0.23177083 0.56901042\n",
      " 0.58854167 0.578125   0.16145833 0.34375    0.33854167 0.34635417\n",
      " 1.         1.         1.         1.         0.22916667 0.57552083\n",
      " 0.57682292 0.57942708 0.17838542 0.34244792 0.34114583 0.34895833\n",
      " 1.         1.         1.         1.         0.17447917 0.4921875\n",
      " 0.4921875  0.48307292 0.13541667 0.30078125 0.29427083 0.30078125\n",
      " 1.         1.         1.         1.         0.2578125  0.45182292\n",
      " 0.45182292 0.44921875 0.18880208 0.31119792 0.3125     0.31640625\n",
      " 1.         1.         1.         1.         0.234375   0.57161458\n",
      " 0.57942708 0.57942708 0.16145833 0.3515625  0.32682292 0.34244792\n",
      " 1.         1.         1.         1.         0.24479167 0.57291667\n",
      " 0.5859375  0.578125   0.16276042 0.33333333 0.3359375  0.34244792\n",
      " 1.         1.         1.         1.         0.19921875 0.49088542\n",
      " 0.48307292 0.47916667 0.13020833 0.29817708 0.296875   0.29947917\n",
      " 1.         1.         1.         1.         0.27083333 0.453125\n",
      " 0.45182292 0.45833333 0.1953125  0.30729167 0.31770833 0.31770833\n",
      " 1.         1.         1.         1.         0.24348958 0.56640625\n",
      " 0.57552083 0.57682292 0.17578125 0.34895833 0.34244792 0.34375\n",
      " 1.         1.         1.         1.         0.22135417 0.5859375\n",
      " 0.578125   0.57421875 0.17578125 0.34375    0.34114583 0.34505208\n",
      " 0.41836196 0.5002218  0.50887812 0.30100203 0.36509663 0.60243471\n",
      " 0.31918667 0.60243302 0.60156553 0.51277647 0.49458677 0.50152219\n",
      " 0.49675803 0.60243359 0.33912035 0.41532884 0.59376826 0.60329883\n",
      " 0.50065526 0.59766662 0.60156497 0.3798265  0.60156891 0.59810289\n",
      " 0.29970333 0.29753714 0.60243246 0.31832312 0.26981519 0.59637242\n",
      " 0.29320588 0.29493861 1.         1.         0.50239193 0.3867546\n",
      " 0.60113432 0.41793018 0.30316879 0.38892248 1.         1.\n",
      " 1.         0.50455024 0.59636735 0.30013679 0.37853174 0.6002674\n",
      " 0.60243415 1.         1.         1.         0.37766144 0.3789607\n",
      " 1.         1.         1.         1.         1.         0.37982763\n",
      " 1.         1.         1.         1.         0.38805555 0.38805217\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.34820957 1.         0.35730048\n",
      " 1.         1.         1.         1.         1.         0.34864191\n",
      " 1.         1.         1.         0.34777273 0.35166827 1.\n",
      " 1.         1.         1.         1.         1.         0.35210455\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99927837 0.99927837 0.99927837 0.99927837\n",
      " 0.99927837 0.99927837 0.99927837 0.99927837 0.99927837 0.99927837\n",
      " 0.99927837 0.99927837 0.99927837 0.99927837 0.99927837 0.99927837\n",
      " 0.99927837 0.99927837 0.99927837 0.99927837 0.99927837 0.99927837\n",
      " 0.99927837 0.99927837 0.99927837 0.99927837 0.99927837 0.99927837\n",
      " 0.99927837 0.99927837 0.99927837 0.99927837 0.99927837 0.99927837\n",
      " 0.99927837 0.99927837 0.99927837 0.99927837 0.99927837 0.99927837\n",
      " 0.99927837 0.99927837 0.99927837 0.99812396 0.99812396 0.99812396\n",
      " 0.99812396 0.99812396 0.99812396 0.99812396 0.99812396 0.99812396\n",
      " 0.99812396 0.99812396 0.99812396 0.99812396 0.99812396 0.99812396\n",
      "        nan        nan 0.99595953 0.99595953 0.99595953]\n",
      "  warnings.warn(\n",
      "\n",
      "Reading models...:   5%|▌         | 1/19 [30:52<9:15:40, 1852.23s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  {'bootstrap': True, 'max_depth': 55, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 901}\n",
      "best score:  nan\n",
      "Model  RandomForestClassifier(warm_start=True)  running time:  1852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "8064 fits failed out of a total of 18432.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2304 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 291, in fit\n",
      "    if self.max_features > 0.0:\n",
      "TypeError: '>' not supported between instances of 'range' and 'float'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4608 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 411, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1152 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 291, in fit\n",
      "    if self.max_features > 0.0:\n",
      "TypeError: '>' not supported between instances of 'range' and 'float'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.06367003 0.08040404 0.05023569 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.39896985 0.40069514 0.40402848 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "6144 fits failed out of a total of 6144.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3069 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 411, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "771 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 291, in fit\n",
      "    if self.max_features > 0.0:\n",
      "TypeError: '>' not supported between instances of 'range' and 'float'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2304 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 291, in fit\n",
      "    if self.max_features > 0.0:\n",
      "TypeError: '>' not supported between instances of 'range' and 'float'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.06367003 0.08040404 0.05023569 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.39896985 0.40069514 0.40402848 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2049 fits failed out of a total of 2049.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "474 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 411, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "177 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 291, in fit\n",
      "    if self.max_features > 0.0:\n",
      "TypeError: '>' not supported between instances of 'range' and 'float'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1398 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 291, in fit\n",
      "    if self.max_features > 0.0:\n",
      "TypeError: '>' not supported between instances of 'range' and 'float'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.06367003 0.08040404 0.05023569 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.39896985 0.40069514 0.40402848 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "684 fits failed out of a total of 684.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "42 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 291, in fit\n",
      "    if self.max_features > 0.0:\n",
      "TypeError: '>' not supported between instances of 'range' and 'float'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "129 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 411, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "513 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 291, in fit\n",
      "    if self.max_features > 0.0:\n",
      "TypeError: '>' not supported between instances of 'range' and 'float'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.06367003 0.08040404 0.05023569 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.39896985 0.40069514 0.40402848 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "228 fits failed out of a total of 228.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "42 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 411, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 291, in fit\n",
      "    if self.max_features > 0.0:\n",
      "TypeError: '>' not supported between instances of 'range' and 'float'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "171 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 291, in fit\n",
      "    if self.max_features > 0.0:\n",
      "TypeError: '>' not supported between instances of 'range' and 'float'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.06367003 0.08040404 0.05023569 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.39896985 0.40069514 0.40402848 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "78 fits failed out of a total of 78.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 411, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 291, in fit\n",
      "    if self.max_features > 0.0:\n",
      "TypeError: '>' not supported between instances of 'range' and 'float'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "57 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 291, in fit\n",
      "    if self.max_features > 0.0:\n",
      "TypeError: '>' not supported between instances of 'range' and 'float'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.06367003 0.08040404 0.05023569 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.39896985 0.40069514 0.40402848 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "\n",
      "Reading models...:  11%|█         | 2/19 [47:51<6:25:55, 1362.08s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  ExtraTreesClassifier(warm_start=True) did not work\n",
      "Model  ExtraTreesClassifier(warm_start=True)  running time:  1018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...:  16%|█▌        | 3/19 [47:58<3:18:17, 743.58s/it] \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  {'alpha': 0.5}\n",
      "best score:  0.08559678319830351\n",
      "Model  BernoulliNB()  running time:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 690, in fit\n",
      "    self._count(X, Y)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1006, in _count\n",
      "    check_non_negative(X, \"ComplementNB (input X)\")\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1249, in check_non_negative\n",
      "    raise ValueError(\"Negative values in data passed to %s\" % whom)\n",
      "ValueError: Negative values in data passed to ComplementNB (input X)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 6.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 690, in fit\n",
      "    self._count(X, Y)\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1006, in _count\n",
      "    check_non_negative(X, \"ComplementNB (input X)\")\n",
      "  File \"C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1249, in check_non_negative\n",
      "    raise ValueError(\"Negative values in data passed to %s\" % whom)\n",
      "ValueError: Negative values in data passed to ComplementNB (input X)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "\n",
      "Reading models...:  21%|██        | 4/19 [48:02<1:52:55, 451.68s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  ComplementNB() did not work\n",
      "Model  ComplementNB()  running time:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...:  26%|██▋       | 5/19 [48:03<1:07:27, 289.11s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  MultinomialNB() did not work\n",
      "Model  MultinomialNB()  running time:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...:  32%|███▏      | 6/19 [48:07<41:38, 192.21s/it]  \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  GaussianNB() did not work\n",
      "Model  GaussianNB()  running time:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...:  37%|███▋      | 7/19 [48:12<26:08, 130.72s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  RadiusNeighborsClassifier() did not work\n",
      "Model  RadiusNeighborsClassifier()  running time:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...:  42%|████▏     | 8/19 [48:16<16:34, 90.38s/it] \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  LogisticRegression() did not work\n",
      "Model  LogisticRegression()  running time:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...:  47%|████▋     | 9/19 [48:20<10:33, 63.40s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  RidgeClassifier() did not work\n",
      "Model  RidgeClassifier()  running time:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...:  53%|█████▎    | 10/19 [1:51:02<3:00:47, 1205.29s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  {'C': 10.0}\n",
      "best score:  0.15216022243707883\n",
      "Model  SVC()  running time:  3762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...:  58%|█████▊    | 11/19 [1:51:05<1:51:39, 837.47s/it] \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  LinearSVC() did not work\n",
      "Model  LinearSVC()  running time:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...:  63%|██████▎   | 12/19 [1:51:09<1:08:06, 583.78s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  NuSVC() did not work\n",
      "Model  NuSVC()  running time:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "Reading models...:  68%|██████▊   | 13/19 [1:59:23<55:40, 556.77s/it]  \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  {}\n",
      "best score:  0.31906050181392404\n",
      "Model  MLPClassifier()  running time:  494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...:  74%|███████▎  | 14/19 [1:59:25<32:24, 388.94s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  NearestCentroid() did not work\n",
      "Model  NearestCentroid()  running time:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...:  79%|███████▉  | 15/19 [1:59:28<18:11, 272.84s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  QuadraticDiscriminantAnalysis() did not work\n",
      "Model  QuadraticDiscriminantAnalysis()  running time:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...:  84%|████████▍ | 16/19 [1:59:41<09:43, 194.64s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  {}\n",
      "best score:  0.31810997059863144\n",
      "Model  KNeighborsClassifier()  running time:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading models...: 100%|██████████| 19/19 [1:59:44<00:00, 378.12s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  LinearDiscriminantAnalysis() did not work\n",
      "Model  LinearDiscriminantAnalysis()  running time:  2\n",
      "model  GaussianProcessClassifier() did not work\n",
      "Model  GaussianProcessClassifier()  running time:  0\n",
      "model  SGDClassifier() did not work\n",
      "Model  SGDClassifier()  running time:  0\n",
      "Program running time:  7184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = dt.now()\n",
    "\n",
    "progress_bar = tqdm(total=len(ensemble_clf), desc='Reading models...')\n",
    "\n",
    "Grid = []\n",
    "\n",
    "for i in range(len(ensemble_clf)):\n",
    "    modelStart = dt.now()\n",
    "    try:\n",
    "        Grid = HalvingGridSearchCV(estimator=ensemble_clf[i], param_grid=parameters_list[i],\n",
    "                                   n_jobs=-1, cv=3, verbose=0).fit(feat_train, lab_train)\n",
    "        print(\"best param: \", Grid.best_params_)\n",
    "        print(\"best score: \", Grid.best_score_)\n",
    "        #base_accuracy = evaluate(ensemble_clf, feat_test, lab_test)\n",
    "        #grid_accuracy = evaluate(Grid.best_estimator, feat_test, lab_test)\n",
    "        #print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))\n",
    "\n",
    "    except:\n",
    "        print(\"model \", ensemble_clf[i], \"did not work\")\n",
    "    progress_bar.update(1)\n",
    "    modelRunning_secs = (dt.now() - modelStart).seconds\n",
    "    print(\"Model \", ensemble_clf[i], \" running time: \", modelRunning_secs)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "running_secs = (dt.now() - start).seconds\n",
    "print(\"Program running time: \", running_secs)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading models...:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#testing cell\n",
    "\n",
    "svc = SVC()\n",
    "lsvc = LinearSVC()\n",
    "nu = NuSVC()\n",
    "mplN = MLPClassifier(batch_size='auto', warm_start=True, max_iter=400)\n",
    "mplS = MLPClassifier(batch_size='auto', warm_start=True, solver='sgd', max_iter=400, early_stopping=True)\n",
    "mplA = MLPClassifier(batch_size='auto', warm_start=True, solver='adam', max_iter=400, early_stopping=True)\n",
    "nc = NearestCentroid()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "kn = KNeighborsClassifier()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "gpc = GaussianProcessClassifier()\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "#ensemble_clf = [svc, lsvc, nu, mplN,mplS,mplA, nc, qda, kn, lda, gpc, sgd]\n",
    "ensemble_clf = [ lsvc, nu, mplN, mplS, mplA]\n",
    "\n",
    "lsvcParam = {\n",
    "    'C': [0.1, 0.5, 1.0, 10.0],\n",
    "}\n",
    "nuParam = {\n",
    "    'nu': [0.1, 1.0],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid', ],\n",
    "    'gamma': ['auto', 'scale']\n",
    "}\n",
    "mplNParam = {\n",
    "    'hidden_layer_sizes': (10,120,10),\n",
    "    'activation': ('identity', 'logistic', 'tanh', 'relu'),\n",
    "    'alpha': (0.000001, 0.00001, 0.0001),\n",
    "    'solver': ('lbfgs', 'sgd', 'adam'),\n",
    "    'shrinking': (True, False),\n",
    "}\n",
    "mplSParam = {\n",
    "    'hidden_layer_sizes': (10,120,10),\n",
    "    'activation': ('identity', 'logistic', 'tanh', 'relu'),\n",
    "    'alpha': (0.000001, 0.00001, 0.0001),\n",
    "    'learning_rate': ('constant', 'invscaling', 'adaptive'),\n",
    "    'momentum': (0.1,0.9,0.1),\n",
    "}\n",
    "mplAParam = {\n",
    "    'hidden_layer_sizes': (10,120,10),\n",
    "    'activation': ('identity', 'logistic', 'tanh', 'relu'),\n",
    "    'alpha': (0.000001, 0.00001, 0.0001),\n",
    "    'beta_1': (0.1,0.9,0.1),\n",
    "    'beta_2': (0.1,0.9,0.1),\n",
    "                   }\n",
    "ncParam = {}\n",
    "qdaParam = {\n",
    "    'reg_param': (0.00001, 0.001, 0.1),\n",
    "    'store_covariance': (True, False),\n",
    "    'tol': (0.0001, 0.01, 0.1),\n",
    "}\n",
    "knParam = {\n",
    "    'n_neighbors': range(2, 30, 10),\n",
    "    'leaf_size': range(2, 40, 15),\n",
    "    'p': (1, 2),\n",
    "    'weights': ('uniform', 'distance'),\n",
    "    'metric': ('minkowski', 'chebyshev', 'euclidean', 'manhattan'),\n",
    "    'algorithm': ('auto', 'brute', 'kd_tree', 'ball_tree')}\n",
    "ldaParam = {'solver': ['svd', 'lsqr', 'eigen'], 'shrinkage': [np.arange(0, 1, 0.2), 'auto'],\n",
    "            'n_components': range(0, 5, 2), 'store_covariance': (True, False)}\n",
    "gpcParam = {}\n",
    "sgdParam = {'loss': ['hinge', 'log', 'modified_huber','squared_hinge', 'perceptron'],\n",
    "            'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "            'alpha': [0.0001, 0.01, 1, 75, 1000],\n",
    "            'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'eta0': [1, 10, 100],\n",
    "            'n_iter': [1, 5, 10]}\n",
    "\n",
    "#parameters_list = [lsvcParam, nuParam, mplNParam, mplSParam, mplAParam, ncParam, qdaParam, knParam, gpcParam, sgdParam]\n",
    "parameters_list = [lsvcParam,nuParam,mplNParam, mplSParam, mplAParam]\n",
    "\n",
    "start = dt.now()\n",
    "\n",
    "progress_bar = tqdm(total=len(ensemble_clf), desc='Reading models...')\n",
    "\n",
    "Grid = []\n",
    "\n",
    "for i in range(len(ensemble_clf)):\n",
    "    modelStart = dt.now()\n",
    "    Grid = HalvingGridSearchCV(estimator=ensemble_clf[i], param_grid=parameters_list[i],\n",
    "                                   n_jobs=-1, cv=3, verbose=0).fit(feat_train, lab_train)\n",
    "    print(\"best param: \", Grid.best_params_)\n",
    "    print(\"best score: \", Grid.best_score_)\n",
    "    #base_accuracy = evaluate(ensemble_clf, feat_test, lab_test)\n",
    "    #grid_accuracy = evaluate(Grid.best_estimator, feat_test, lab_test)\n",
    "    #print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))\n",
    "\n",
    "    progress_bar.update(1)\n",
    "    modelRunning_secs = (dt.now() - modelStart).seconds\n",
    "    print(\"Model \", ensemble_clf[i], \" running time: \", modelRunning_secs)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "running_secs = (dt.now() - start).seconds\n",
    "print(\"Program running time: \", running_secs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVC was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#test cell\n",
    "\n",
    "svcParam = {'C': [0.001, 1, 50, 100, 'auto'],\n",
    "            'gamma': [0.001, 0.1, 1.0, 100, 1000],\n",
    "            'kernel': ['rbf', 'linear', 'sigmoid']\n",
    "            }\n",
    "lsvcParam = {\n",
    "    'C': [0.1, 0.5, 1.0, 10.0],\n",
    "}\n",
    "nuParam = {\n",
    "    'nu': [0.1, 1.0],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid', ],\n",
    "    'gamma': ['auto', 'scale']\n",
    "}\n",
    "\n",
    "\n",
    "svc = SVC(C=50,gamma=0.1,kernel='rbf')\n",
    "lsvc = LinearSVC(C=.5)\n",
    "nu = NuSVC(nu=0.1,kernel='linear',gamma='auto')\n",
    "\n",
    "clf = svc\n",
    "clf.fit(feat_train, lab_train)\n",
    "\n",
    "print(clf.score(feat_test, lab_test))  #This automatically makes predictions on feat_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}