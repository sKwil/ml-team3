{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d16ee7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary modules from repository\n",
    "from model.data.pipeline import utils as ut\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3031ba1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#dataframe of all monthly data\n",
    "df = ut.load_sql_as_df('SELECT * From MonthlyDataModel;')\n",
    "\n",
    "#dataframe of month averages to fill in bad values\n",
    "monthAvg = ut.load_sql_as_df('SELECT * From MonthlyAverages;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Getting features and choosing labels. Fill NaN spots with NaN text to manipulate them\n",
    "labels = df[\"state\"]\n",
    "#['region', 'latitude', 'longitude', 'elevation', 'region'] are all dropped automatically\n",
    "df = df.fillna('NaN')\n",
    "\n",
    "stateNump = df[\"state\"].to_numpy()\n",
    "\n",
    "# Changing columns in to months to help compare\n",
    "featSer = df[\"month\"].to_numpy()\n",
    "prcpIntM = monthAvg[\"prcpInt\"].to_numpy()\n",
    "prcpFreqM = monthAvg[\"prcpFreq\"].to_numpy()\n",
    "temp_max_normalM = monthAvg[\"temp_max_normal\"].to_numpy()\n",
    "temp_min_normalM = monthAvg[\"temp_min_normal\"].to_numpy()\n",
    "snow_depthM = monthAvg[\"snowInt\"].to_numpy()\n",
    "snow_daysM = monthAvg[\"snowFreq\"].to_numpy()\n",
    "cloudsM = monthAvg[\"clouds\"].to_numpy()\n",
    "dewM = monthAvg[\"dew_point\"].to_numpy()\n",
    "heatM = monthAvg[\"heat_index\"].to_numpy()\n",
    "pressureM = monthAvg[\"pressure\"].to_numpy()\n",
    "windM = monthAvg[\"wind_speed\"].to_numpy()\n",
    "windCalmM = monthAvg[\"wind_calm_percentage\"].to_numpy()\n",
    "\n",
    "prcp_normRay = df[\"prcp_normal\"].to_numpy()\n",
    "prcp_days_tRay = df[\"prcp_days_t\"].to_numpy()\n",
    "temp_max_normalRay = df[\"temp_max_normal\"].to_numpy()\n",
    "temp_min_normalRay = df[\"temp_min_normal\"].to_numpy()\n",
    "snow_depthRay = df[\"snow_depth_days\"].to_numpy()\n",
    "snow_daysRay = df[\"snow_days_t\"].to_numpy()\n",
    "cloudsRay = df[\"clouds\"].to_numpy()\n",
    "dewRay = df[\"dew_point\"].to_numpy()\n",
    "heatRay = df[\"heat_index\"].to_numpy()\n",
    "pressureRay = df[\"pressure\"].to_numpy()\n",
    "windRay = df[\"wind_speed\"].to_numpy()\n",
    "windCalmRay = df[\"wind_calm_percentage\"].to_numpy()\n",
    "\n",
    "#replacing bad values\n",
    "for i in range(len(featSer)):\n",
    "    if prcp_days_tRay[i] == 'NaN' or prcp_days_tRay[i] == -9999 or prcp_days_tRay[i] == -8888 or prcp_days_tRay[\n",
    "        i] == -7777 or prcp_days_tRay[i] == -6666 or prcp_days_tRay[i] == -5555:\n",
    "        prcp_days_tRay[i] = prcpFreqM[featSer[i] - 1]\n",
    "    if temp_max_normalRay[i] == 'NaN' or temp_max_normalRay[i] == -9999 or temp_max_normalRay[i] == -8888 or temp_max_normalRay[i] == -7777 or temp_max_normalRay[i] == -6666 or temp_max_normalRay[i] == -5555:\n",
    "        temp_max_normalRay[i] = temp_max_normalM[featSer[i] - 1]\n",
    "    if temp_min_normalRay[i] == 'NaN' or temp_min_normalRay[i] == -9999 or temp_min_normalRay[i] == -8888 or temp_min_normalRay[i] == -7777 or temp_min_normalRay[i] == -6666 or temp_min_normalRay[i] == -5555:\n",
    "        temp_min_normalRay[i] = temp_min_normalM[featSer[i] - 1]\n",
    "    if snow_daysRay[i] == 'NaN' or snow_daysRay[i] == -9999 or snow_daysRay[i] == -8888 or snow_daysRay[i] == -7777 or snow_daysRay[i] ==-6666 or snow_daysRay[i] == -5555:\n",
    "        snow_daysRay[i] = snow_daysM[featSer[i] - 1]\n",
    "    if cloudsRay[i] == 'NaN' or cloudsRay[i] == -9999 or cloudsRay[i] == -8888 or cloudsRay[i] == -7777 or cloudsRay[i] == -6666 or cloudsRay[i] == -5555:\n",
    "        cloudsRay[i] = cloudsM[featSer[i] - 1]\n",
    "    if dewRay[i] == 'NaN' or dewRay[i] == -9999 or dewRay[i] == -8888 or dewRay[i] == -7777 or dewRay[i] == -6666 or dewRay[i] == -5555:\n",
    "        dewRay[i] = dewM[featSer[i] - 1]\n",
    "    if heatRay[i] == 'NaN' or heatRay[i] == -9999 or heatRay[i] == -8888 or heatRay[i] == -7777 or heatRay[i] == -6666 or heatRay[i] == -5555:\n",
    "        heatRay[i] = heatM[featSer[i] - 1]\n",
    "    if windRay[i] == 'NaN' or windRay[i] == -9999 or windRay[i] == -8888 or windRay[i] == -7777 or windRay[i] == -6666 or windRay[i] == -5555:\n",
    "        windRay[i] = windM[featSer[i] - 1]\n",
    "\n",
    "mount = featSer\n",
    "ocean = featSer\n",
    "\n",
    "mountSwitcher = {\n",
    "'AL':0,\n",
    "'AR':0,\n",
    "'AZ':0,\n",
    "'CA':0,\n",
    "'CO':0,\n",
    "'CT':0,\n",
    "'DE':0,\n",
    "'FL':0,\n",
    "'GA':0,\n",
    "'HI':0,\n",
    "'IA':0,\n",
    "'ID':0,\n",
    "'IL':0,\n",
    "'IN':0,\n",
    "'KS':0,\n",
    "'KY':0,\n",
    "'LA':0,\n",
    "'MA':0,\n",
    "'MD':0,\n",
    "'ME':0,\n",
    "'MI':0,\n",
    "'MN':0,\n",
    "'MO':0,\n",
    "'MS':0,\n",
    "'MT':0,\n",
    "'NC':0,\n",
    "'ND':0,\n",
    "'NE':0,\n",
    "'NH':0,\n",
    "'NJ':0,\n",
    "'NM':0,\n",
    "'NV':0,\n",
    "'NY':0,\n",
    "'OH':0,\n",
    "'OK':0,\n",
    "'OR':0,\n",
    "'PA':0,\n",
    "'RI':0,\n",
    "'SC':0,\n",
    "'SD':0,\n",
    "'TN':0,\n",
    "'TX':0,\n",
    "'UT':0,\n",
    "'VA':0,\n",
    "'VT':0,\n",
    "'WA':0,\n",
    "'WI':0,\n",
    "'WV':0,\n",
    "'WY':0\n",
    "}\n",
    "\n",
    "oceanSwitcher = {\n",
    "'AL':0,\n",
    "'AR':0,\n",
    "'AZ':0,\n",
    "'CA':0,\n",
    "'CO':0,\n",
    "'CT':0,\n",
    "'DE':0,\n",
    "'FL':0,\n",
    "'GA':0,\n",
    "'HI':0,\n",
    "'IA':0,\n",
    "'ID':0,\n",
    "'IL':0,\n",
    "'IN':0,\n",
    "'KS':0,\n",
    "'KY':0,\n",
    "'LA':0,\n",
    "'MA':0,\n",
    "'MD':0,\n",
    "'ME':0,\n",
    "'MI':0,\n",
    "'MN':0,\n",
    "'MO':0,\n",
    "'MS':0,\n",
    "'MT':0,\n",
    "'NC':0,\n",
    "'ND':0,\n",
    "'NE':0,\n",
    "'NH':0,\n",
    "'NJ':0,\n",
    "'NM':0,\n",
    "'NV':0,\n",
    "'NY':0,\n",
    "'OH':0,\n",
    "'OK':0,\n",
    "'OR':0,\n",
    "'PA':0,\n",
    "'RI':0,\n",
    "'SC':0,\n",
    "'SD':0,\n",
    "'TN':0,\n",
    "'TX':0,\n",
    "'UT':0,\n",
    "'VA':0,\n",
    "'VT':0,\n",
    "'WA':0,\n",
    "'WI':0,\n",
    "'WV':0,\n",
    "'WY':0\n",
    "}\n",
    "\n",
    "for i in range(len(state)):\n",
    "    mount[i] = mountSwitcher[state[i]]\n",
    "    mount[i] = oceanSwitcher[state[i]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(featSer)):\n",
    "    if prcp_days_tRay[i] == 'NaN' or prcp_days_tRay[i] == -9999 or prcp_days_tRay[i] == -8888 or prcp_days_tRay[\n",
    "        i] == -7777 or prcp_days_tRay[i] == -6666 or prcp_days_tRay[i] == -5555:\n",
    "        prcp_days_tRay[i] = prcpFreqM[featSer[i] - 1]\n",
    "\n",
    "df1 = df.copy()\n",
    "# Recreating filled dataset\n",
    "df = pd.DataFrame({'state': labels, 'month' : featSer, 'prcp_days_tRay': prcp_days_tRay,\n",
    "                   \"temp_max_normalRay\": temp_max_normalRay, \"temp_min_normalRay\": temp_min_normalRay,\n",
    "                   \"snow_daysRay\": snow_daysRay, \"cloudsRay\": cloudsRay,\n",
    "                   \"dewRay\": dewRay, \"heatRay\": heatRay, \"windRay\": windRay})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       state  month prcp_days_tRay temp_max_normalRay temp_min_normalRay  \\\n0         AL      1           69.0          41.924644          21.303576   \n1         AL      2           65.0          45.985372          24.106816   \n2         AL      3           62.0          54.495133          31.252366   \n3         AL      4           48.0          64.407005          39.586609   \n4         AL      5           48.0          73.406937           48.77541   \n...      ...    ...            ...                ...                ...   \n117031    NE      8      25.909684               85.4               62.7   \n117032    NE      9      46.810539               77.8               53.6   \n117033    NE     10      47.409751               65.2               40.6   \n117034    NE     11      49.541899               49.7               28.0   \n117035    NE     12      50.036534               36.9               17.1   \n\n       snow_daysRay  cloudsRay     dewRay    heatRay   windRay  \n0               0.0  55.667977  26.341895  35.417982  8.593669  \n1               0.0  55.013862  28.228661  38.559721  8.813964  \n2       -297.336583  52.051446  33.052022  45.700434  9.329369  \n3               0.0  49.932187   39.67777  54.337107  9.386922  \n4               0.0  48.941521  48.669454    63.3096  8.659783  \n...             ...        ...        ...        ...       ...  \n117031   -32.307496  40.020323  59.955251  74.535821  7.050787  \n117032  -337.711363  41.015647  53.890063  67.271141  7.402396  \n117033  -656.829311  45.018233   44.25134  56.376711  7.768246  \n117034  -363.569282   51.45818  35.445112  45.895488  8.266765  \n117035  -291.094614  55.725457   28.84527  37.656348  8.419217  \n\n[117036 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>month</th>\n      <th>prcp_days_tRay</th>\n      <th>temp_max_normalRay</th>\n      <th>temp_min_normalRay</th>\n      <th>snow_daysRay</th>\n      <th>cloudsRay</th>\n      <th>dewRay</th>\n      <th>heatRay</th>\n      <th>windRay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AL</td>\n      <td>1</td>\n      <td>69.0</td>\n      <td>41.924644</td>\n      <td>21.303576</td>\n      <td>0.0</td>\n      <td>55.667977</td>\n      <td>26.341895</td>\n      <td>35.417982</td>\n      <td>8.593669</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AL</td>\n      <td>2</td>\n      <td>65.0</td>\n      <td>45.985372</td>\n      <td>24.106816</td>\n      <td>0.0</td>\n      <td>55.013862</td>\n      <td>28.228661</td>\n      <td>38.559721</td>\n      <td>8.813964</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AL</td>\n      <td>3</td>\n      <td>62.0</td>\n      <td>54.495133</td>\n      <td>31.252366</td>\n      <td>-297.336583</td>\n      <td>52.051446</td>\n      <td>33.052022</td>\n      <td>45.700434</td>\n      <td>9.329369</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AL</td>\n      <td>4</td>\n      <td>48.0</td>\n      <td>64.407005</td>\n      <td>39.586609</td>\n      <td>0.0</td>\n      <td>49.932187</td>\n      <td>39.67777</td>\n      <td>54.337107</td>\n      <td>9.386922</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AL</td>\n      <td>5</td>\n      <td>48.0</td>\n      <td>73.406937</td>\n      <td>48.77541</td>\n      <td>0.0</td>\n      <td>48.941521</td>\n      <td>48.669454</td>\n      <td>63.3096</td>\n      <td>8.659783</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>117031</th>\n      <td>NE</td>\n      <td>8</td>\n      <td>25.909684</td>\n      <td>85.4</td>\n      <td>62.7</td>\n      <td>-32.307496</td>\n      <td>40.020323</td>\n      <td>59.955251</td>\n      <td>74.535821</td>\n      <td>7.050787</td>\n    </tr>\n    <tr>\n      <th>117032</th>\n      <td>NE</td>\n      <td>9</td>\n      <td>46.810539</td>\n      <td>77.8</td>\n      <td>53.6</td>\n      <td>-337.711363</td>\n      <td>41.015647</td>\n      <td>53.890063</td>\n      <td>67.271141</td>\n      <td>7.402396</td>\n    </tr>\n    <tr>\n      <th>117033</th>\n      <td>NE</td>\n      <td>10</td>\n      <td>47.409751</td>\n      <td>65.2</td>\n      <td>40.6</td>\n      <td>-656.829311</td>\n      <td>45.018233</td>\n      <td>44.25134</td>\n      <td>56.376711</td>\n      <td>7.768246</td>\n    </tr>\n    <tr>\n      <th>117034</th>\n      <td>NE</td>\n      <td>11</td>\n      <td>49.541899</td>\n      <td>49.7</td>\n      <td>28.0</td>\n      <td>-363.569282</td>\n      <td>51.45818</td>\n      <td>35.445112</td>\n      <td>45.895488</td>\n      <td>8.266765</td>\n    </tr>\n    <tr>\n      <th>117035</th>\n      <td>NE</td>\n      <td>12</td>\n      <td>50.036534</td>\n      <td>36.9</td>\n      <td>17.1</td>\n      <td>-291.094614</td>\n      <td>55.725457</td>\n      <td>28.84527</td>\n      <td>37.656348</td>\n      <td>8.419217</td>\n    </tr>\n  </tbody>\n</table>\n<p>117036 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       state  month prcp_days_tRay temp_max_normalRay temp_min_normalRay  \\\n0         AL      1           69.0          41.924644          21.303576   \n1         AL      2           65.0          45.985372          24.106816   \n2         AL      3           62.0          54.495133          31.252366   \n3         AL      4           48.0          64.407005          39.586609   \n4         AL      5           48.0          73.406937           48.77541   \n...      ...    ...            ...                ...                ...   \n117031    NE      8      25.909684               85.4               62.7   \n117032    NE      9      46.810539               77.8               53.6   \n117033    NE     10      47.409751               65.2               40.6   \n117034    NE     11      49.541899               49.7               28.0   \n117035    NE     12      50.036534               36.9               17.1   \n\n       snow_daysRay  cloudsRay     dewRay    heatRay   windRay longitude_bin  \n0               0.0  55.667977  26.341895  35.417982  8.593669             3  \n1               0.0  55.013862  28.228661  38.559721  8.813964             3  \n2       -297.336583  52.051446  33.052022  45.700434  9.329369             3  \n3               0.0  49.932187   39.67777  54.337107  9.386922             3  \n4               0.0  48.941521  48.669454    63.3096  8.659783             3  \n...             ...        ...        ...        ...       ...           ...  \n117031   -32.307496  40.020323  59.955251  74.535821  7.050787             3  \n117032  -337.711363  41.015647  53.890063  67.271141  7.402396             3  \n117033  -656.829311  45.018233   44.25134  56.376711  7.768246             3  \n117034  -363.569282   51.45818  35.445112  45.895488  8.266765             3  \n117035  -291.094614  55.725457   28.84527  37.656348  8.419217             3  \n\n[117036 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>month</th>\n      <th>prcp_days_tRay</th>\n      <th>temp_max_normalRay</th>\n      <th>temp_min_normalRay</th>\n      <th>snow_daysRay</th>\n      <th>cloudsRay</th>\n      <th>dewRay</th>\n      <th>heatRay</th>\n      <th>windRay</th>\n      <th>longitude_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AL</td>\n      <td>1</td>\n      <td>69.0</td>\n      <td>41.924644</td>\n      <td>21.303576</td>\n      <td>0.0</td>\n      <td>55.667977</td>\n      <td>26.341895</td>\n      <td>35.417982</td>\n      <td>8.593669</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AL</td>\n      <td>2</td>\n      <td>65.0</td>\n      <td>45.985372</td>\n      <td>24.106816</td>\n      <td>0.0</td>\n      <td>55.013862</td>\n      <td>28.228661</td>\n      <td>38.559721</td>\n      <td>8.813964</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AL</td>\n      <td>3</td>\n      <td>62.0</td>\n      <td>54.495133</td>\n      <td>31.252366</td>\n      <td>-297.336583</td>\n      <td>52.051446</td>\n      <td>33.052022</td>\n      <td>45.700434</td>\n      <td>9.329369</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AL</td>\n      <td>4</td>\n      <td>48.0</td>\n      <td>64.407005</td>\n      <td>39.586609</td>\n      <td>0.0</td>\n      <td>49.932187</td>\n      <td>39.67777</td>\n      <td>54.337107</td>\n      <td>9.386922</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AL</td>\n      <td>5</td>\n      <td>48.0</td>\n      <td>73.406937</td>\n      <td>48.77541</td>\n      <td>0.0</td>\n      <td>48.941521</td>\n      <td>48.669454</td>\n      <td>63.3096</td>\n      <td>8.659783</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>117031</th>\n      <td>NE</td>\n      <td>8</td>\n      <td>25.909684</td>\n      <td>85.4</td>\n      <td>62.7</td>\n      <td>-32.307496</td>\n      <td>40.020323</td>\n      <td>59.955251</td>\n      <td>74.535821</td>\n      <td>7.050787</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>117032</th>\n      <td>NE</td>\n      <td>9</td>\n      <td>46.810539</td>\n      <td>77.8</td>\n      <td>53.6</td>\n      <td>-337.711363</td>\n      <td>41.015647</td>\n      <td>53.890063</td>\n      <td>67.271141</td>\n      <td>7.402396</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>117033</th>\n      <td>NE</td>\n      <td>10</td>\n      <td>47.409751</td>\n      <td>65.2</td>\n      <td>40.6</td>\n      <td>-656.829311</td>\n      <td>45.018233</td>\n      <td>44.25134</td>\n      <td>56.376711</td>\n      <td>7.768246</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>117034</th>\n      <td>NE</td>\n      <td>11</td>\n      <td>49.541899</td>\n      <td>49.7</td>\n      <td>28.0</td>\n      <td>-363.569282</td>\n      <td>51.45818</td>\n      <td>35.445112</td>\n      <td>45.895488</td>\n      <td>8.266765</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>117035</th>\n      <td>NE</td>\n      <td>12</td>\n      <td>50.036534</td>\n      <td>36.9</td>\n      <td>17.1</td>\n      <td>-291.094614</td>\n      <td>55.725457</td>\n      <td>28.84527</td>\n      <td>37.656348</td>\n      <td>8.419217</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>117036 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adds another column showing which bin every row falls into. The bins are based on the temp_max_normalRay column\n",
    "df['longitude_bin'] = pd.cut(df1['longitude'],\n",
    "                             bins=[-400, -125, -100, -75, np.inf],\n",
    "                             labels=[1, 2, 3, 4])\n",
    "df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2,\n",
    "                               random_state=42)  #n_splits is training date, test_size is target\n",
    "\n",
    "for train_index, test_index in split.split(df, df[\"longitude_bin\"]):  #shows it is an iterateable object\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "\n",
    "#SELECT COUNT(*) GROUP BY region;\n",
    "#     check if we need strat_sampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "lab_train = strat_train_set['state']\n",
    "feat_train = strat_train_set.drop(['state', 'longitude_bin'], axis=1)\n",
    "lab_test = strat_test_set['state']\n",
    "feat_test = strat_test_set.drop(['state', 'longitude_bin'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'from sklearn.model_selection import train_test_split\\n\\nfeat_train, feat_test, lab_train, lab_test = train_test_split(featPrepped, labels, random_state=42)\\n# stratify by city for separating training and testing. stratified sampling'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler = StandardScaler()  # makes 0 the average\n",
    "feat_train = scaler.fit_transform(feat_train)\n",
    "feat_train = scaler2.fit_transform(feat_train)\n",
    "feat_train += 1\n",
    "\n",
    "\"\"\"from sklearn.model_selection import train_test_split\n",
    "\n",
    "feat_train, feat_test, lab_train, lab_test = train_test_split(featPrepped, labels, random_state=42)\n",
    "# stratify by city for separating training and testing. stratified sampling\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.45454545, 1.18894685, 1.80140187, ..., 1.74688859, 1.74753299,\n        1.14415524],\n       [1.36363636, 1.29019608, 1.73831776, ..., 1.64292851, 1.66114153,\n        1.15967809],\n       [1.09090909, 1.16470588, 1.56619938, ..., 1.36825312, 1.4010354 ,\n        1.16314962],\n       ...,\n       [2.        , 1.12941176, 1.62928349, ..., 1.37653888, 1.3915415 ,\n        1.15426152],\n       [1.81818182, 1.18431373, 1.66199377, ..., 1.66770136, 1.63219236,\n        1.06086056],\n       [1.18181818, 1.21011523, 1.60124611, ..., 1.43306757, 1.47607993,\n        1.17475444]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef48f30a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa8d6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "rc = RidgeClassifier()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "\n",
    "rfParam = {\"max_depth\": range(5, 30, 5), \"min_samples_leaf\": range(1, 30, 10),\n",
    "           \"n_estimators\": range(1, 15, 4),\n",
    "           'bootstrap': [True,False],\n",
    "           'max_features': [1, 7, 'auto', 'sqrt'],\n",
    "           'warm_start': [True,False]}\n",
    "exParamOob = {\n",
    "    'n_estimators': range(1,15, 4),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": range(1,30, 5),\n",
    "    'min_samples_split': range(2, 15, 4),\n",
    "    'min_samples_leaf': range(1, 25, 6),\n",
    "    'oob_score': [True, False],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', range(50, 200, 75)],\n",
    "    'bootstrap': [True],\n",
    "    'warm_start': [True, False],\n",
    "}\n",
    "exParam = {\n",
    "    'n_estimators': range(1,15, 4),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": range(1,30, 5),\n",
    "    'min_samples_split': range(2, 15, 4),\n",
    "    'min_samples_leaf': range(1, 25, 6),\n",
    "    'max_features': ['auto', 'sqrt', 'log2', range(50, 200, 75)],\n",
    "    'bootstrap': [True,False],\n",
    "    'warm_start': [True, False],\n",
    "}\n",
    "rnParam = {'radius': np.arange(0.8, 1.5, 0.4),\n",
    "           'weights': ['uniform', 'distance']}\n",
    "lrParam = {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'penalty': ['l2','none'],\n",
    "           'C': [10, 0.1, 0.001]}\n",
    "rcParam = {'alpha': [0.1, 0.5, 1.0]}\n",
    "svcParam = {'C': [0.01, 1, 3 'auto'],\n",
    "            'gamma': [0.1, 1.0, 2],\n",
    "            'kernel': ['rbf', 'linear', 'sigmoid']\n",
    "            }\n",
    "ldaParam = {'solver': ['svd', 'lsqr', 'eigen'], 'shrinkage': [np.arange(0, 1, 0.2), 'auto'],\n",
    "            'n_components': range(0, 5, 2), 'store_covariance': (True, False)}\n",
    "gpcParam = {}\n",
    "sgdParam = {'loss': ['hinge', 'log', 'modified_huber','squared_hinge', 'perceptron'],\n",
    "            'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "            'alpha': [0.0001, 0.01, 1, 75, 1000],\n",
    "            'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'eta0': [1, 10, 100],\n",
    "            'n_iter': [1, 5, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading models...:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  {'alpha': 0.02, 'hidden_layer_sizes': (60, 80, 100, 120), 'solver': 'adam'}\n",
      "best score:  0.31326030419260326\n",
      "Program running time:  2510\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\ntanh, 0.01, 120, lbfgs\\ntanh, 0.1, 100, lbfgs      20\\ntanh, 0.1, 100,50 , adam\\ntan, .5, 200,100,200, lbfgs\\ntan, 0.1, (60,300,100)adam\\n.05, (300,200,50,300) adam    31%\\n'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing cell\n",
    "\n",
    "\n",
    "mplN = MLPClassifier(batch_size='auto', warm_start=True, max_iter=400, activation = 'tanh')\n",
    "\n",
    "\n",
    "#ensemble_clf = [mplN,mplS,mplA]\n",
    "ensemble_clf = mplN\n",
    "\n",
    "mplNParam = {\n",
    "    'hidden_layer_sizes': [(60,80,100,120),(100,80,70,60)],\n",
    "    'alpha': (0.05,0.08,0.02,0.008),\n",
    "    'solver': ('lbfgs','adam'),\n",
    "}\n",
    "#(300,200,50,300),(400,200,150,100,60)\n",
    "\n",
    "parameters_list = mplNParam\n",
    "start = dt.now()\n",
    "\n",
    "Grid = HalvingGridSearchCV(estimator=ensemble_clf, param_grid=parameters_list,\n",
    "                                   n_jobs=-1, cv=3, verbose=0).fit(feat_train, lab_train)\n",
    "print(\"best param: \", Grid.best_params_)\n",
    "print(\"best score: \", Grid.best_score_)\n",
    "\n",
    "running_secs = (dt.now() - start).seconds\n",
    "print(\"Program running time: \", running_secs)\n",
    "\n",
    "\"\"\"\n",
    "tanh, 0.01, 120, lbfgs\n",
    "tanh, 0.1, 100, lbfgs      20\n",
    "tanh, 0.1, 100,50 , adam\n",
    "tan, .5, 200,100,200, lbfgs\n",
    "tan, 0.1, (60,300,100)adam\n",
    ".05, (300,200,50,300) adam    31%\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mplA = MLPClassifier(batch_size='auto', warm_start=True, solver='adam', max_iter=400, early_stopping=True)\n",
    "\n",
    "\n",
    "#ensemble_clf = [mplN,mplS,mplA]\n",
    "ensemble_clf = mplA\n",
    "\n",
    "mplAParam = {\n",
    "    'hidden_layer_sizes': [(60,80,100,120),(100,80,70,60)],\n",
    "    'activation': ('identity', 'tanh', 'relu'),\n",
    "    'alpha': (0.00005, 0.00001, 0.000005),\n",
    "    'beta_1': (0.4,0.5,0.6),\n",
    "    'beta_2': (0.6,0.7,0.8),\n",
    "}\n",
    "\n",
    "parameters_list = mplAParam\n",
    "start = dt.now()\n",
    "\n",
    "Grid = HalvingGridSearchCV(estimator=ensemble_clf, param_grid=parameters_list,\n",
    "                                   n_jobs=-1, cv=3, verbose=0).fit(feat_train, lab_train)\n",
    "print(\"best param: \", Grid.best_params_)\n",
    "print(\"best score: \", Grid.best_score_)\n",
    "\n",
    "running_secs = (dt.now() - start).seconds\n",
    "print(\"Program running time: \", running_secs)\n",
    "\n",
    "\"\"\"\n",
    "tanh,1e-5,1=.5,2=.7,(150,100,50,10)\n",
    "tan, 5e-6,1=.6,2=.7,(60,300,100)   26%\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svcParam = {'C': [4, 2, 3],\n",
    "            'gamma': [0.1, 1.0, 2,'scale','auto'],\n",
    "            'kernel': ['rbf', 'linear', 'sigmoid']\n",
    "            }\n",
    "\n",
    "#ensemble_clf = [mplN,mplS,mplA]\n",
    "ensemble_clf = svc\n",
    "\n",
    "\n",
    "\n",
    "parameters_list = svcParam\n",
    "start = dt.now()\n",
    "\n",
    "Grid = HalvingGridSearchCV(estimator=ensemble_clf, param_grid=parameters_list,\n",
    "                                   n_jobs=-1, cv=3, verbose=0).fit(feat_train, lab_train)\n",
    "print(\"best param: \", Grid.best_params_)\n",
    "print(\"best score: \", Grid.best_score_)\n",
    "\n",
    "running_secs = (dt.now() - start).seconds\n",
    "print(\"Program running time: \", running_secs)\n",
    "\n",
    "\"\"\"\n",
    "3,2,rbf    25%\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#testing cell\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "ensemble_clf = rf\n",
    "\n",
    "\n",
    "rfParam = {\"max_depth\": range(12, 18, 2), \"min_samples_leaf\": range(1, 5, 2),\n",
    "           \"n_estimators\": range(9, 15, 2),\n",
    "           'bootstrap': [True,False],\n",
    "           'max_features': ['auto', 'sqrt'],\n",
    "           'warm_start': [True,False]}\n",
    "\n",
    "parameters_list = rfParam\n",
    "start = dt.now()\n",
    "\n",
    "Grid = HalvingGridSearchCV(estimator=ensemble_clf, param_grid=parameters_list,\n",
    "                                   n_jobs=-1, cv=3, verbose=0).fit(feat_train, lab_train)\n",
    "print(\"best param: \", Grid.best_params_)\n",
    "print(\"best score: \", Grid.best_score_)\n",
    "\n",
    "running_secs = (dt.now() - start).seconds\n",
    "print(\"Program running time: \", running_secs)\n",
    "\n",
    "\"\"\"\n",
    "rf {'bootstrap': False, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 13, 'warm_start': False}    33%\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kn = KNeighborsClassifier()\n",
    "knParam = {\n",
    "    'n_neighbors': range(2, 30, 10),\n",
    "    'leaf_size': range(2, 40, 15),\n",
    "    'p': (1, 2),\n",
    "    'weights': ('uniform', 'distance'),\n",
    "    'metric': ('minkowski', 'chebyshev', 'euclidean', 'manhattan'),\n",
    "    'algorithm': ('auto', 'brute', 'kd_tree', 'ball_tree')}\n",
    "\n",
    "ensemble_clf = kn\n",
    "parameters_list = knParam\n",
    "start = dt.now()\n",
    "\n",
    "Grid = HalvingGridSearchCV(estimator=ensemble_clf, param_grid=parameters_list,\n",
    "                                   n_jobs=-1, cv=3, verbose=0).fit(feat_train, lab_train)\n",
    "print(\"best param: \", Grid.best_params_)\n",
    "print(\"best score: \", Grid.best_score_)\n",
    "\n",
    "running_secs = (dt.now() - start).seconds\n",
    "print(\"Program running time: \", running_secs)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", probability=True, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "\n",
    "ada_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}