{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "38d16ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultioutputClassifier, used when predicting two different attributes. Is also a multilable classifier.\n",
    "# Not useful, also predicts the month, this might serve as testing\n",
    "# Import necessary libraries            shift f6   to rename\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import necessary modules from repository\n",
    "from model.data.pipeline import aggregate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c3031ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            city month  temperature   humidity     pressure  wind_speed  \\\n0    Albuquerque    01   270.272182  66.064693  1017.595395    2.158991   \n1    Albuquerque    02   273.247977  59.198556  1002.113117    2.110710   \n2    Albuquerque    03   277.633500  46.305921  1022.492325    2.372807   \n3    Albuquerque    04   281.128437  42.245241  1017.913774    2.674132   \n4    Albuquerque    05   285.056028  44.270997  1018.783875    2.422172   \n..           ...   ...          ...        ...          ...         ...   \n319      Seattle    08   288.256538  81.549462  1021.889247    1.472043   \n320      Seattle    09   285.754826  87.371111  1019.393333    1.695556   \n321      Seattle    10   282.342478  91.931655  1020.478417    2.010791   \n322      Seattle    11   279.136062  90.236620  1020.972770    2.179343   \n323      Seattle    12   276.501070  87.659760  1020.765540    2.310796   \n\n         rain      snow     cloud       fog  extreme_weather  \n0    0.031950  0.053250  0.519661  0.011742         0.000546  \n1    0.034483  0.023988  0.570315  0.003298         0.004798  \n2    0.039103  0.000820  0.586546  0.000273         0.003828  \n3    0.055383  0.003391  0.656683  0.006499         0.005369  \n4    0.105337  0.000843  0.638483  0.000843         0.023596  \n..        ...       ...       ...       ...              ...  \n319  0.082796  0.000000  0.383602  0.089247         0.046505  \n320  0.211448  0.000000  0.529869  0.103918         0.022228  \n321  0.321855  0.000000  0.623002  0.132118         0.013504  \n322  0.305517  0.003273  0.587424  0.153109         0.019635  \n323  0.345034  0.004898  0.615238  0.201088         0.026939  \n\n[324 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>month</th>\n      <th>temperature</th>\n      <th>humidity</th>\n      <th>pressure</th>\n      <th>wind_speed</th>\n      <th>rain</th>\n      <th>snow</th>\n      <th>cloud</th>\n      <th>fog</th>\n      <th>extreme_weather</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albuquerque</td>\n      <td>01</td>\n      <td>270.272182</td>\n      <td>66.064693</td>\n      <td>1017.595395</td>\n      <td>2.158991</td>\n      <td>0.031950</td>\n      <td>0.053250</td>\n      <td>0.519661</td>\n      <td>0.011742</td>\n      <td>0.000546</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albuquerque</td>\n      <td>02</td>\n      <td>273.247977</td>\n      <td>59.198556</td>\n      <td>1002.113117</td>\n      <td>2.110710</td>\n      <td>0.034483</td>\n      <td>0.023988</td>\n      <td>0.570315</td>\n      <td>0.003298</td>\n      <td>0.004798</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albuquerque</td>\n      <td>03</td>\n      <td>277.633500</td>\n      <td>46.305921</td>\n      <td>1022.492325</td>\n      <td>2.372807</td>\n      <td>0.039103</td>\n      <td>0.000820</td>\n      <td>0.586546</td>\n      <td>0.000273</td>\n      <td>0.003828</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albuquerque</td>\n      <td>04</td>\n      <td>281.128437</td>\n      <td>42.245241</td>\n      <td>1017.913774</td>\n      <td>2.674132</td>\n      <td>0.055383</td>\n      <td>0.003391</td>\n      <td>0.656683</td>\n      <td>0.006499</td>\n      <td>0.005369</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albuquerque</td>\n      <td>05</td>\n      <td>285.056028</td>\n      <td>44.270997</td>\n      <td>1018.783875</td>\n      <td>2.422172</td>\n      <td>0.105337</td>\n      <td>0.000843</td>\n      <td>0.638483</td>\n      <td>0.000843</td>\n      <td>0.023596</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>319</th>\n      <td>Seattle</td>\n      <td>08</td>\n      <td>288.256538</td>\n      <td>81.549462</td>\n      <td>1021.889247</td>\n      <td>1.472043</td>\n      <td>0.082796</td>\n      <td>0.000000</td>\n      <td>0.383602</td>\n      <td>0.089247</td>\n      <td>0.046505</td>\n    </tr>\n    <tr>\n      <th>320</th>\n      <td>Seattle</td>\n      <td>09</td>\n      <td>285.754826</td>\n      <td>87.371111</td>\n      <td>1019.393333</td>\n      <td>1.695556</td>\n      <td>0.211448</td>\n      <td>0.000000</td>\n      <td>0.529869</td>\n      <td>0.103918</td>\n      <td>0.022228</td>\n    </tr>\n    <tr>\n      <th>321</th>\n      <td>Seattle</td>\n      <td>10</td>\n      <td>282.342478</td>\n      <td>91.931655</td>\n      <td>1020.478417</td>\n      <td>2.010791</td>\n      <td>0.321855</td>\n      <td>0.000000</td>\n      <td>0.623002</td>\n      <td>0.132118</td>\n      <td>0.013504</td>\n    </tr>\n    <tr>\n      <th>322</th>\n      <td>Seattle</td>\n      <td>11</td>\n      <td>279.136062</td>\n      <td>90.236620</td>\n      <td>1020.972770</td>\n      <td>2.179343</td>\n      <td>0.305517</td>\n      <td>0.003273</td>\n      <td>0.587424</td>\n      <td>0.153109</td>\n      <td>0.019635</td>\n    </tr>\n    <tr>\n      <th>323</th>\n      <td>Seattle</td>\n      <td>12</td>\n      <td>276.501070</td>\n      <td>87.659760</td>\n      <td>1020.765540</td>\n      <td>2.310796</td>\n      <td>0.345034</td>\n      <td>0.004898</td>\n      <td>0.615238</td>\n      <td>0.201088</td>\n      <td>0.026939</td>\n    </tr>\n  </tbody>\n</table>\n<p>324 rows Ã— 11 columns</p>\n</div>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = aggregate.get_agg_data_frame()\n",
    "df = df.reset_index(level=['city','month'])\n",
    "\n",
    "\n",
    "'''Ideas to make more powerful:\n",
    "add distance to ocean/mountains, add std for weather\n",
    "make month not a label\n",
    "'''\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "labels = df[[\"city\",\"month\"]]\n",
    "features = df.drop(['city','month'], axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "featPrepped = scaler.fit_transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feat_train, feat_test, lab_train, lab_test = train_test_split(featPrepped, labels, random_state = 42)\n",
    "\n",
    "#lab_train = lab_train.to_numpy()\n",
    "#lab_test = lab_test.to_numpy()\n",
    "\n",
    "type(lab_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "0.09876543209876543"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "clf = MultiOutputClassifier(rfc, n_jobs=-1)\n",
    "clf.fit(feat_train, lab_train)\n",
    "\n",
    "clf.score(feat_test,lab_test)\n",
    "# low scare shows we do not have enough destinctions between cities."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4355817b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a15a761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.08641975308641975"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "clf = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "clf.fit(feat_train, lab_train)\n",
    "\n",
    "clf.score(feat_test,lab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "656fd4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6bf397da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "SELECT DISTINCT weather_description\n",
    "FROM USWeather;\n",
    "\n",
    "SELECT <columns>\n",
    "FROM <table>\n",
    "#WHERE <condition>\n",
    "#ORDER BY <column> <asc/desc>;\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4423fd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ef48f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier,  GradientBoostingClassifier\n",
    "\n",
    "\n",
    "log_reg_params = [{\"C\":0.01}, {\"C\":0.1}, {\"C\":1}, {\"C\":10}]\n",
    "dec_tree_params = [{\"criterion\": \"gini\"}, {\"criterion\": \"entropy\"}]\n",
    "rand_for_params = [{\"criterion\": \"gini\"}, {\"criterion\": \"entropy\"}]\n",
    "kneighbors_params = [{\"n_neighbors\":3}, {\"n_neighbors\":5}]\n",
    "naive_bayes_params = [{}]\n",
    "svc_params = [{\"C\":0.01}, {\"C\":0.1}, {\"C\":1}, {\"C\":10}]\n",
    "\n",
    "modelclasses = [\n",
    "    [\"log regression\", LogisticRegression, log_reg_params],\n",
    "    [\"decision tree\", DecisionTreeClassifier, dec_tree_params],\n",
    "    [\"random forest\", RandomForestClassifier, rand_for_params],\n",
    "    [\"k neighbors\", KNeighborsClassifier, kneighbors_params],\n",
    "    [\"naive bayes\", GaussianNB, naive_bayes_params],\n",
    "    [\"support vector machines\", SVC, svc_params]\n",
    "]\n",
    "\n",
    "\n",
    "insights = []\n",
    "for modelname, Model, params_list in modelclasses:\n",
    "    for params in params_list:\n",
    "        model = Model(**params)\n",
    "        model.fit(x_train, y_train)\n",
    "        score = model.score(x_test, y_test)\n",
    "        insights.append((modelname, model, params, score))\n",
    "\n",
    "insights.sort(key=lambda x:x[-1], reverse=True)\n",
    "for modelname, model, params, score in insights:\n",
    "    print(modelname, params, score)\n",
    "\n",
    "x = features\n",
    "y = labels\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "afaa8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, \\\n",
    "    Perceptron, PassiveAggressiveClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, DotProduct, Matern, StationaryKernelMixin, WhiteKernel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from utilities import *\n",
    "from Parameters import *\n",
    "\n",
    "\n",
    "def gen_classification_data(n=None):\n",
    "    \"\"\"\n",
    "    uses the iris data\n",
    "    :return: x, y\n",
    "    \"\"\"\n",
    "\n",
    "    x = features\n",
    "    y = labels\n",
    "\n",
    "    if n:\n",
    "        half = int(n/2)\n",
    "        np.concatenate((x[:half], x[-half:]), 1), np.concatenate((y[:half], y[-half:]), 0)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "linear_models_n_params = [\n",
    "    (SGDClassifier,\n",
    "     {'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge'],\n",
    "      'alpha': [0.0001, 0.001, 0.1],\n",
    "      **penalty_12none\n",
    "      }),\n",
    "\n",
    "    (LogisticRegression,\n",
    "     {**penalty_12, **max_iter, **tol, ** warm_start, **C,\n",
    "      'solver': ['liblinear']\n",
    "      }),\n",
    "\n",
    "    (Perceptron,\n",
    "     {**penalty_all, **alpha, **n_iter, **eta0, **warm_start\n",
    "      }),\n",
    "\n",
    "    (PassiveAggressiveClassifier,\n",
    "     {**C, **n_iter, **warm_start,\n",
    "      'loss': ['hinge', 'squared_hinge'],\n",
    "      })\n",
    "]\n",
    "\n",
    "linear_models_n_params_small = linear_models_n_params\n",
    "\n",
    "svm_models_n_params = [\n",
    "    (SVC,\n",
    "     {**C, **kernel, **degree, **gamma, **coef0, **shrinking, **tol, **max_iter_inf2}),\n",
    "\n",
    "    (NuSVC,\n",
    "     {**nu, **kernel, **degree, **gamma, **coef0, **shrinking, **tol\n",
    "      }),\n",
    "\n",
    "    (LinearSVC,\n",
    "     { **C, **penalty_12, **tol, **max_iter,\n",
    "       'loss': ['hinge', 'squared_hinge'],\n",
    "       })\n",
    "]\n",
    "\n",
    "svm_models_n_params_small = [\n",
    "    (SVC,\n",
    "     {**kernel, **degree, **shrinking\n",
    "      }),\n",
    "\n",
    "    (NuSVC,\n",
    "     {**nu_small, **kernel, **degree, **shrinking\n",
    "      }),\n",
    "\n",
    "    (LinearSVC,\n",
    "     { **C_small,\n",
    "       'penalty': ['l2'],\n",
    "       'loss': ['hinge', 'squared_hinge'],\n",
    "       })\n",
    "]\n",
    "\n",
    "neighbor_models_n_params = [\n",
    "\n",
    "    (KMeans,\n",
    "     {'algorithm': ['auto', 'full', 'elkan'],\n",
    "      'init': ['k-means++', 'random']}),\n",
    "\n",
    "    (KNeighborsClassifier,\n",
    "     {**n_neighbors, **neighbor_algo, **neighbor_leaf_size, **neighbor_metric,\n",
    "      'weights': ['uniform', 'distance'],\n",
    "      'p': [1, 2]\n",
    "      }),\n",
    "\n",
    "    (NearestCentroid,\n",
    "     {**neighbor_metric,\n",
    "      'shrink_threshold': [1e-3, 1e-2, 0.1, 0.5, 0.9, 2]\n",
    "      }),\n",
    "\n",
    "    (RadiusNeighborsClassifier,\n",
    "     {**neighbor_radius, **neighbor_algo, **neighbor_leaf_size, **neighbor_metric,\n",
    "      'weights': ['uniform', 'distance'],\n",
    "      'p': [1, 2],\n",
    "      'outlier_label': [-1]\n",
    "      })\n",
    "]\n",
    "\n",
    "gaussianprocess_models_n_params = [\n",
    "    (GaussianProcessClassifier,\n",
    "     {**warm_start,\n",
    "      'kernel': [RBF(), ConstantKernel(), DotProduct(), WhiteKernel()],\n",
    "      'max_iter_predict': [500],\n",
    "      'n_restarts_optimizer': [3],\n",
    "      })\n",
    "]\n",
    "\n",
    "bayes_models_n_params = [\n",
    "    (GaussianNB, {})\n",
    "]\n",
    "\n",
    "nn_models_n_params = [\n",
    "    (MLPClassifier,\n",
    "     { 'hidden_layer_sizes': [(16,), (64,), (100,), (32, 32)],\n",
    "       'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "       **alpha, **learning_rate, **tol, **warm_start,\n",
    "       'batch_size': ['auto', 50],\n",
    "       'max_iter': [1000],\n",
    "       'early_stopping': [True, False],\n",
    "       'epsilon': [1e-8, 1e-5]\n",
    "       })\n",
    "]\n",
    "\n",
    "nn_models_n_params_small = [\n",
    "    (MLPClassifier,\n",
    "     { 'hidden_layer_sizes': [(64,), (32, 64)],\n",
    "       'batch_size': ['auto', 50],\n",
    "       'activation': ['identity', 'tanh', 'relu'],\n",
    "       'max_iter': [500],\n",
    "       'early_stopping': [True],\n",
    "       **learning_rate_small\n",
    "       })\n",
    "]\n",
    "\n",
    "tree_models_n_params = [\n",
    "\n",
    "    (RandomForestClassifier,\n",
    "     {'criterion': ['gini', 'entropy'],\n",
    "      **max_features, **n_estimators, **max_depth,\n",
    "      **min_samples_split, **min_impurity_split, **warm_start, **min_samples_leaf,\n",
    "      }),\n",
    "\n",
    "    (DecisionTreeClassifier,\n",
    "     {'criterion': ['gini', 'entropy'],\n",
    "      **max_features, **max_depth, **min_samples_split, **min_impurity_split, **min_samples_leaf\n",
    "      }),\n",
    "\n",
    "    (ExtraTreesClassifier,\n",
    "     {**n_estimators, **max_features, **max_depth,\n",
    "      **min_samples_split, **min_samples_leaf, **min_impurity_split, **warm_start,\n",
    "      'criterion': ['gini', 'entropy']})\n",
    "]\n",
    "\n",
    "\n",
    "tree_models_n_params_small = [\n",
    "\n",
    "    (RandomForestClassifier,\n",
    "     {**max_features_small, **n_estimators_small, **min_samples_split, **max_depth_small, **min_samples_leaf\n",
    "      }),\n",
    "\n",
    "    (DecisionTreeClassifier,\n",
    "     {**max_features_small, **max_depth_small, **min_samples_split, **min_samples_leaf\n",
    "      }),\n",
    "\n",
    "    (ExtraTreesClassifier,\n",
    "     {**n_estimators_small, **max_features_small, **max_depth_small,\n",
    "      **min_samples_split, **min_samples_leaf})\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def run_linear_models(x, y, small = True, normalize_x = True):\n",
    "    return big_loop(linear_models_n_params_small if small else linear_models_n_params,\n",
    "                    StandardScaler().fit_transform(x) if normalize_x else x, y, isClassification=True)\n",
    "\n",
    "def run_svm_models(x, y, small = True, normalize_x = True):\n",
    "    return big_loop(svm_models_n_params_small if small else svm_models_n_params,\n",
    "                    StandardScaler().fit_transform(x) if normalize_x else x, y, isClassification=True)\n",
    "\n",
    "def run_neighbor_models(x, y, normalize_x = True):\n",
    "    return big_loop(neighbor_models_n_params,\n",
    "                    StandardScaler().fit_transform(x) if normalize_x else x, y, isClassification=True)\n",
    "\n",
    "def run_gaussian_models(x, y, normalize_x = True):\n",
    "    return big_loop(gaussianprocess_models_n_params,\n",
    "                    StandardScaler().fit_transform(x) if normalize_x else x, y, isClassification=True)\n",
    "\n",
    "def run_nn_models(x, y, small = True, normalize_x = True):\n",
    "    return big_loop(nn_models_n_params_small if small else nn_models_n_params,\n",
    "                    StandardScaler().fit_transform(x) if normalize_x else x, y, isClassification=True)\n",
    "\n",
    "def run_tree_models(x, y, small = True, normalize_x = True):\n",
    "    return big_loop(tree_models_n_params_small if small else tree_models_n_params,\n",
    "                    StandardScaler().fit_transform(x) if normalize_x else x, y, isClassification=True)\n",
    "\n",
    "def run_all(x, y, small = True, normalize_x = True, n_jobs=cpu_count()-1):\n",
    "\n",
    "    all_params = (linear_models_n_params_small if small else linear_models_n_params) + \\\n",
    "                 (nn_models_n_params_small if small else nn_models_n_params) + \\\n",
    "                 ([] if small else gaussianprocess_models_n_params) + \\\n",
    "                 neighbor_models_n_params + \\\n",
    "                 (svm_models_n_params_small if small else svm_models_n_params) + \\\n",
    "                 (tree_models_n_params_small if small else tree_models_n_params)\n",
    "\n",
    "    return big_loop(all_params,\n",
    "                    StandardScaler().fit_transform(x) if normalize_x else x, y,\n",
    "                    isClassification=True, n_jobs=n_jobs)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    x, y = gen_classification_data()\n",
    "    run_all(x, y, n_jobs=1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}