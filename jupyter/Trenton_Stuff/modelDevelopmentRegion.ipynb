{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d16ee7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary modules from repository\n",
    "from model.data.pipeline import utils as ut\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3031ba1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#dataframe of all monthly data\n",
    "df = ut.load_sql_as_df('SELECT * From MonthlyDataModel;')\n",
    "\n",
    "#dataframe of month averages to fill in bad values\n",
    "monthAvg = ut.load_sql_as_df('SELECT * From MonthlyAverages;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Getting features and choosing labels. Fill NaN spots with NaN text to manipulate them\n",
    "labels = df[\"region\"]\n",
    "#['region', 'latitude', 'longitude', 'elevation', 'region'] are all dropped automatically\n",
    "df = df.fillna('NaN')\n",
    "\n",
    "stateNump = df[\"region\"].to_numpy()\n",
    "\n",
    "# Changing columns in to months to help compare\n",
    "featSer = df[\"month\"].to_numpy()\n",
    "prcpIntM = monthAvg[\"prcpInt\"].to_numpy()\n",
    "prcpFreqM = monthAvg[\"prcpFreq\"].to_numpy()\n",
    "temp_max_normalM = monthAvg[\"temp_max_normal\"].to_numpy()\n",
    "temp_min_normalM = monthAvg[\"temp_min_normal\"].to_numpy()\n",
    "snow_depthM = monthAvg[\"snowInt\"].to_numpy()\n",
    "snow_daysM = monthAvg[\"snowFreq\"].to_numpy()\n",
    "cloudsM = monthAvg[\"clouds\"].to_numpy()\n",
    "dewM = monthAvg[\"dew_point\"].to_numpy()\n",
    "heatM = monthAvg[\"heat_index\"].to_numpy()\n",
    "pressureM = monthAvg[\"pressure\"].to_numpy()\n",
    "windM = monthAvg[\"wind_speed\"].to_numpy()\n",
    "windCalmM = monthAvg[\"wind_calm_percentage\"].to_numpy()\n",
    "\n",
    "prcp_normRay = df[\"prcp_normal\"].to_numpy()\n",
    "prcp_days_tRay = df[\"prcp_days_t\"].to_numpy()\n",
    "temp_max_normalRay = df[\"temp_max_normal\"].to_numpy()\n",
    "temp_min_normalRay = df[\"temp_min_normal\"].to_numpy()\n",
    "snow_depthRay = df[\"snow_depth_days\"].to_numpy()\n",
    "snow_daysRay = df[\"snow_days_t\"].to_numpy()\n",
    "cloudsRay = df[\"clouds\"].to_numpy()\n",
    "dewRay = df[\"dew_point\"].to_numpy()\n",
    "heatRay = df[\"heat_index\"].to_numpy()\n",
    "pressureRay = df[\"pressure\"].to_numpy()\n",
    "windRay = df[\"wind_speed\"].to_numpy()\n",
    "windCalmRay = df[\"wind_calm_percentage\"].to_numpy()\n",
    "\n",
    "#replacing bad values\n",
    "for i in range(len(featSer)):\n",
    "    if prcp_days_tRay[i] == 'NaN' or prcp_days_tRay[i] == -9999 or prcp_days_tRay[i] == -8888 or prcp_days_tRay[\n",
    "        i] == -7777 or prcp_days_tRay[i] == -6666 or prcp_days_tRay[i] == -5555:\n",
    "        prcp_days_tRay[i] = prcpFreqM[featSer[i] - 1]\n",
    "    if temp_max_normalRay[i] == 'NaN' or temp_max_normalRay[i] == -9999 or temp_max_normalRay[i] == -8888 or temp_max_normalRay[i] == -7777 or temp_max_normalRay[i] == -6666 or temp_max_normalRay[i] == -5555:\n",
    "        temp_max_normalRay[i] = temp_max_normalM[featSer[i] - 1]\n",
    "    if temp_min_normalRay[i] == 'NaN' or temp_min_normalRay[i] == -9999 or temp_min_normalRay[i] == -8888 or temp_min_normalRay[i] == -7777 or temp_min_normalRay[i] == -6666 or temp_min_normalRay[i] == -5555:\n",
    "        temp_min_normalRay[i] = temp_min_normalM[featSer[i] - 1]\n",
    "    if snow_daysRay[i] == 'NaN' or snow_daysRay[i] == -9999 or snow_daysRay[i] == -8888 or snow_daysRay[i] == -7777 or snow_daysRay[i] ==-6666 or snow_daysRay[i] == -5555:\n",
    "        snow_daysRay[i] = snow_daysM[featSer[i] - 1]\n",
    "    if cloudsRay[i] == 'NaN' or cloudsRay[i] == -9999 or cloudsRay[i] == -8888 or cloudsRay[i] == -7777 or cloudsRay[i] == -6666 or cloudsRay[i] == -5555:\n",
    "        cloudsRay[i] = cloudsM[featSer[i] - 1]\n",
    "    if dewRay[i] == 'NaN' or dewRay[i] == -9999 or dewRay[i] == -8888 or dewRay[i] == -7777 or dewRay[i] == -6666 or dewRay[i] == -5555:\n",
    "        dewRay[i] = dewM[featSer[i] - 1]\n",
    "    if heatRay[i] == 'NaN' or heatRay[i] == -9999 or heatRay[i] == -8888 or heatRay[i] == -7777 or heatRay[i] == -6666 or heatRay[i] == -5555:\n",
    "        heatRay[i] = heatM[featSer[i] - 1]\n",
    "    if windRay[i] == 'NaN' or windRay[i] == -9999 or windRay[i] == -8888 or windRay[i] == -7777 or windRay[i] == -6666 or windRay[i] == -5555:\n",
    "        windRay[i] = windM[featSer[i] - 1]\n",
    "\n",
    "for i in range(len(featSer)):\n",
    "    if prcp_days_tRay[i] == 'NaN' or prcp_days_tRay[i] == -9999 or prcp_days_tRay[i] == -8888 or prcp_days_tRay[\n",
    "        i] == -7777 or prcp_days_tRay[i] == -6666 or prcp_days_tRay[i] == -5555:\n",
    "        prcp_days_tRay[i] = prcpFreqM[featSer[i] - 1]\n",
    "\n",
    "df1 = df.copy()\n",
    "# Recreating filled dataset\n",
    "df = pd.DataFrame({'region': labels, 'month' : featSer, 'prcp_days_tRay': prcp_days_tRay,\n",
    "                   \"temp_max_normalRay\": temp_max_normalRay, \"temp_min_normalRay\": temp_min_normalRay,\n",
    "                   \"snow_daysRay\": snow_daysRay, \"cloudsRay\": cloudsRay,\n",
    "                   \"dewRay\": dewRay, \"heatRay\": heatRay, \"windRay\": windRay})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "            region  month prcp_days_tRay temp_max_normalRay  \\\n0       south east      1           69.0          41.924644   \n1       south east      2           65.0          45.985372   \n2       south east      3           62.0          54.495133   \n3       south east      4           48.0          64.407005   \n4       south east      5           48.0          73.406937   \n...            ...    ...            ...                ...   \n117031     midwest      8      25.909684               85.4   \n117032     midwest      9      46.810539               77.8   \n117033     midwest     10      47.409751               65.2   \n117034     midwest     11      49.541899               49.7   \n117035     midwest     12      50.036534               36.9   \n\n       temp_min_normalRay snow_daysRay  cloudsRay     dewRay    heatRay  \\\n0               21.303576          0.0  55.667977  26.341895  35.417982   \n1               24.106816          0.0  55.013862  28.228661  38.559721   \n2               31.252366  -297.336583  52.051446  33.052022  45.700434   \n3               39.586609          0.0  49.932187   39.67777  54.337107   \n4                48.77541          0.0  48.941521  48.669454    63.3096   \n...                   ...          ...        ...        ...        ...   \n117031               62.7   -32.307496  40.020323  59.955251  74.535821   \n117032               53.6  -337.711363  41.015647  53.890063  67.271141   \n117033               40.6  -656.829311  45.018233   44.25134  56.376711   \n117034               28.0  -363.569282   51.45818  35.445112  45.895488   \n117035               17.1  -291.094614  55.725457   28.84527  37.656348   \n\n         windRay  \n0       8.593669  \n1       8.813964  \n2       9.329369  \n3       9.386922  \n4       8.659783  \n...          ...  \n117031  7.050787  \n117032  7.402396  \n117033  7.768246  \n117034  8.266765  \n117035  8.419217  \n\n[117036 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region</th>\n      <th>month</th>\n      <th>prcp_days_tRay</th>\n      <th>temp_max_normalRay</th>\n      <th>temp_min_normalRay</th>\n      <th>snow_daysRay</th>\n      <th>cloudsRay</th>\n      <th>dewRay</th>\n      <th>heatRay</th>\n      <th>windRay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>south east</td>\n      <td>1</td>\n      <td>69.0</td>\n      <td>41.924644</td>\n      <td>21.303576</td>\n      <td>0.0</td>\n      <td>55.667977</td>\n      <td>26.341895</td>\n      <td>35.417982</td>\n      <td>8.593669</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>south east</td>\n      <td>2</td>\n      <td>65.0</td>\n      <td>45.985372</td>\n      <td>24.106816</td>\n      <td>0.0</td>\n      <td>55.013862</td>\n      <td>28.228661</td>\n      <td>38.559721</td>\n      <td>8.813964</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>south east</td>\n      <td>3</td>\n      <td>62.0</td>\n      <td>54.495133</td>\n      <td>31.252366</td>\n      <td>-297.336583</td>\n      <td>52.051446</td>\n      <td>33.052022</td>\n      <td>45.700434</td>\n      <td>9.329369</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>south east</td>\n      <td>4</td>\n      <td>48.0</td>\n      <td>64.407005</td>\n      <td>39.586609</td>\n      <td>0.0</td>\n      <td>49.932187</td>\n      <td>39.67777</td>\n      <td>54.337107</td>\n      <td>9.386922</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>south east</td>\n      <td>5</td>\n      <td>48.0</td>\n      <td>73.406937</td>\n      <td>48.77541</td>\n      <td>0.0</td>\n      <td>48.941521</td>\n      <td>48.669454</td>\n      <td>63.3096</td>\n      <td>8.659783</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>117031</th>\n      <td>midwest</td>\n      <td>8</td>\n      <td>25.909684</td>\n      <td>85.4</td>\n      <td>62.7</td>\n      <td>-32.307496</td>\n      <td>40.020323</td>\n      <td>59.955251</td>\n      <td>74.535821</td>\n      <td>7.050787</td>\n    </tr>\n    <tr>\n      <th>117032</th>\n      <td>midwest</td>\n      <td>9</td>\n      <td>46.810539</td>\n      <td>77.8</td>\n      <td>53.6</td>\n      <td>-337.711363</td>\n      <td>41.015647</td>\n      <td>53.890063</td>\n      <td>67.271141</td>\n      <td>7.402396</td>\n    </tr>\n    <tr>\n      <th>117033</th>\n      <td>midwest</td>\n      <td>10</td>\n      <td>47.409751</td>\n      <td>65.2</td>\n      <td>40.6</td>\n      <td>-656.829311</td>\n      <td>45.018233</td>\n      <td>44.25134</td>\n      <td>56.376711</td>\n      <td>7.768246</td>\n    </tr>\n    <tr>\n      <th>117034</th>\n      <td>midwest</td>\n      <td>11</td>\n      <td>49.541899</td>\n      <td>49.7</td>\n      <td>28.0</td>\n      <td>-363.569282</td>\n      <td>51.45818</td>\n      <td>35.445112</td>\n      <td>45.895488</td>\n      <td>8.266765</td>\n    </tr>\n    <tr>\n      <th>117035</th>\n      <td>midwest</td>\n      <td>12</td>\n      <td>50.036534</td>\n      <td>36.9</td>\n      <td>17.1</td>\n      <td>-291.094614</td>\n      <td>55.725457</td>\n      <td>28.84527</td>\n      <td>37.656348</td>\n      <td>8.419217</td>\n    </tr>\n  </tbody>\n</table>\n<p>117036 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "            region  month prcp_days_tRay temp_max_normalRay  \\\n0       south east      1           69.0          41.924644   \n1       south east      2           65.0          45.985372   \n2       south east      3           62.0          54.495133   \n3       south east      4           48.0          64.407005   \n4       south east      5           48.0          73.406937   \n...            ...    ...            ...                ...   \n117031     midwest      8      25.909684               85.4   \n117032     midwest      9      46.810539               77.8   \n117033     midwest     10      47.409751               65.2   \n117034     midwest     11      49.541899               49.7   \n117035     midwest     12      50.036534               36.9   \n\n       temp_min_normalRay snow_daysRay  cloudsRay     dewRay    heatRay  \\\n0               21.303576          0.0  55.667977  26.341895  35.417982   \n1               24.106816          0.0  55.013862  28.228661  38.559721   \n2               31.252366  -297.336583  52.051446  33.052022  45.700434   \n3               39.586609          0.0  49.932187   39.67777  54.337107   \n4                48.77541          0.0  48.941521  48.669454    63.3096   \n...                   ...          ...        ...        ...        ...   \n117031               62.7   -32.307496  40.020323  59.955251  74.535821   \n117032               53.6  -337.711363  41.015647  53.890063  67.271141   \n117033               40.6  -656.829311  45.018233   44.25134  56.376711   \n117034               28.0  -363.569282   51.45818  35.445112  45.895488   \n117035               17.1  -291.094614  55.725457   28.84527  37.656348   \n\n         windRay longitude_bin  \n0       8.593669             3  \n1       8.813964             3  \n2       9.329369             3  \n3       9.386922             3  \n4       8.659783             3  \n...          ...           ...  \n117031  7.050787             3  \n117032  7.402396             3  \n117033  7.768246             3  \n117034  8.266765             3  \n117035  8.419217             3  \n\n[117036 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region</th>\n      <th>month</th>\n      <th>prcp_days_tRay</th>\n      <th>temp_max_normalRay</th>\n      <th>temp_min_normalRay</th>\n      <th>snow_daysRay</th>\n      <th>cloudsRay</th>\n      <th>dewRay</th>\n      <th>heatRay</th>\n      <th>windRay</th>\n      <th>longitude_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>south east</td>\n      <td>1</td>\n      <td>69.0</td>\n      <td>41.924644</td>\n      <td>21.303576</td>\n      <td>0.0</td>\n      <td>55.667977</td>\n      <td>26.341895</td>\n      <td>35.417982</td>\n      <td>8.593669</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>south east</td>\n      <td>2</td>\n      <td>65.0</td>\n      <td>45.985372</td>\n      <td>24.106816</td>\n      <td>0.0</td>\n      <td>55.013862</td>\n      <td>28.228661</td>\n      <td>38.559721</td>\n      <td>8.813964</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>south east</td>\n      <td>3</td>\n      <td>62.0</td>\n      <td>54.495133</td>\n      <td>31.252366</td>\n      <td>-297.336583</td>\n      <td>52.051446</td>\n      <td>33.052022</td>\n      <td>45.700434</td>\n      <td>9.329369</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>south east</td>\n      <td>4</td>\n      <td>48.0</td>\n      <td>64.407005</td>\n      <td>39.586609</td>\n      <td>0.0</td>\n      <td>49.932187</td>\n      <td>39.67777</td>\n      <td>54.337107</td>\n      <td>9.386922</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>south east</td>\n      <td>5</td>\n      <td>48.0</td>\n      <td>73.406937</td>\n      <td>48.77541</td>\n      <td>0.0</td>\n      <td>48.941521</td>\n      <td>48.669454</td>\n      <td>63.3096</td>\n      <td>8.659783</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>117031</th>\n      <td>midwest</td>\n      <td>8</td>\n      <td>25.909684</td>\n      <td>85.4</td>\n      <td>62.7</td>\n      <td>-32.307496</td>\n      <td>40.020323</td>\n      <td>59.955251</td>\n      <td>74.535821</td>\n      <td>7.050787</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>117032</th>\n      <td>midwest</td>\n      <td>9</td>\n      <td>46.810539</td>\n      <td>77.8</td>\n      <td>53.6</td>\n      <td>-337.711363</td>\n      <td>41.015647</td>\n      <td>53.890063</td>\n      <td>67.271141</td>\n      <td>7.402396</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>117033</th>\n      <td>midwest</td>\n      <td>10</td>\n      <td>47.409751</td>\n      <td>65.2</td>\n      <td>40.6</td>\n      <td>-656.829311</td>\n      <td>45.018233</td>\n      <td>44.25134</td>\n      <td>56.376711</td>\n      <td>7.768246</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>117034</th>\n      <td>midwest</td>\n      <td>11</td>\n      <td>49.541899</td>\n      <td>49.7</td>\n      <td>28.0</td>\n      <td>-363.569282</td>\n      <td>51.45818</td>\n      <td>35.445112</td>\n      <td>45.895488</td>\n      <td>8.266765</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>117035</th>\n      <td>midwest</td>\n      <td>12</td>\n      <td>50.036534</td>\n      <td>36.9</td>\n      <td>17.1</td>\n      <td>-291.094614</td>\n      <td>55.725457</td>\n      <td>28.84527</td>\n      <td>37.656348</td>\n      <td>8.419217</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>117036 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adds another column showing which bin every row falls into. The bins are based on the temp_max_normalRay column\n",
    "df['longitude_bin'] = pd.cut(df1['longitude'],\n",
    "                             bins=[-400, -125, -100, -75, np.inf],\n",
    "                             labels=[1, 2, 3, 4])\n",
    "df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2,\n",
    "                               random_state=42)  #n_splits is training date, test_size is target\n",
    "\n",
    "for train_index, test_index in split.split(df, df[\"longitude_bin\"]):  #shows it is an iterateable object\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "\n",
    "#SELECT COUNT(*) GROUP BY region;\n",
    "#     check if we need strat_sampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "lab_train = strat_train_set['region']\n",
    "feat_train = strat_train_set.drop(['region', 'longitude_bin'], axis=1)\n",
    "lab_test = strat_test_set['region']\n",
    "feat_test = strat_test_set.drop(['region', 'longitude_bin'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'from sklearn.model_selection import train_test_split\\n\\nfeat_train, feat_test, lab_train, lab_test = train_test_split(featPrepped, labels, random_state=42)\\n# stratify by city for separating training and testing. stratified sampling'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler = StandardScaler()  # makes 0 the average\n",
    "feat_train = scaler.fit_transform(feat_train)\n",
    "feat_train = scaler2.fit_transform(feat_train)\n",
    "feat_train += 1\n",
    "\n",
    "\"\"\"from sklearn.model_selection import train_test_split\n",
    "\n",
    "feat_train, feat_test, lab_train, lab_test = train_test_split(featPrepped, labels, random_state=42)\n",
    "# stratify by city for separating training and testing. stratified sampling\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.45454545, 1.18894685, 1.80140187, ..., 1.74688859, 1.74753299,\n        1.14415524],\n       [1.36363636, 1.29019608, 1.73831776, ..., 1.64292851, 1.66114153,\n        1.15967809],\n       [1.09090909, 1.16470588, 1.56619938, ..., 1.36825312, 1.4010354 ,\n        1.16314962],\n       ...,\n       [2.        , 1.12941176, 1.62928349, ..., 1.37653888, 1.3915415 ,\n        1.15426152],\n       [1.81818182, 1.18431373, 1.66199377, ..., 1.66770136, 1.63219236,\n        1.06086056],\n       [1.18181818, 1.21011523, 1.60124611, ..., 1.43306757, 1.47607993,\n        1.17475444]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from datetime import datetime as dt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "rc = RidgeClassifier()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "\n",
    "rfParam = {\"max_depth\": range(5, 30, 5), \"min_samples_leaf\": range(1, 30, 10),\n",
    "           \"n_estimators\": range(1, 15, 4),\n",
    "           'bootstrap': [True,False],\n",
    "           'max_features': [1, 7, 'auto', 'sqrt'],\n",
    "           'warm_start': [True,False]}\n",
    "exParamOob = {\n",
    "    'n_estimators': range(1,15, 4),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": range(1,30, 5),\n",
    "    'min_samples_split': range(2, 15, 4),\n",
    "    'min_samples_leaf': range(1, 25, 6),\n",
    "    'oob_score': [True, False],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', range(50, 200, 75)],\n",
    "    'bootstrap': [True],\n",
    "    'warm_start': [True, False],\n",
    "}\n",
    "exParam = {\n",
    "    'n_estimators': range(1,15, 4),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": range(1,30, 5),\n",
    "    'min_samples_split': range(2, 15, 4),\n",
    "    'min_samples_leaf': range(1, 25, 6),\n",
    "    'max_features': ['auto', 'sqrt', 'log2', range(50, 200, 75)],\n",
    "    'bootstrap': [True,False],\n",
    "    'warm_start': [True, False],\n",
    "}\n",
    "rnParam = {'radius': np.arange(0.8, 1.5, 0.4),\n",
    "           'weights': ['uniform', 'distance']}\n",
    "lrParam = {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'penalty': ['l2','none'],\n",
    "           'C': [10, 0.1, 0.001]}\n",
    "rcParam = {'alpha': [0.1, 0.5, 1.0]}\n",
    "svcParam = {'C': [0.01, 1, 3 'auto'],\n",
    "            'gamma': [0.1, 1.0, 2],\n",
    "            'kernel': ['rbf', 'linear', 'sigmoid']\n",
    "            }\n",
    "ldaParam = {'solver': ['svd', 'lsqr', 'eigen'], 'shrinkage': [np.arange(0, 1, 0.2), 'auto'],\n",
    "            'n_components': range(0, 5, 2), 'store_covariance': (True, False)}\n",
    "gpcParam = {}\n",
    "sgdParam = {'loss': ['hinge', 'log', 'modified_huber','squared_hinge', 'perceptron'],\n",
    "            'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "            'alpha': [0.0001, 0.01, 1, 75, 1000],\n",
    "            'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'eta0': [1, 10, 100],\n",
    "            'n_iter': [1, 5, 10]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#finished!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "mplN = MLPClassifier(batch_size='auto', warm_start=True, max_iter=400, activation = 'tanh')\n",
    "\n",
    "\n",
    "#ensemble_clf = [mplN,mplS,mplA]\n",
    "ensemble_clf = mplN\n",
    "\n",
    "mplNParam = {\n",
    "    'hidden_layer_sizes': [(60,80,100,120),(100,80,70,60)],\n",
    "    'alpha': (0.05,0.08,0.02,0.008),\n",
    "    'solver': ('lbfgs','adam'),\n",
    "}\n",
    "#(300,200,50,300),(400,200,150,100,60)\n",
    "\n",
    "parameters_list = mplNParam\n",
    "start = dt.now()\n",
    "\n",
    "Grid = HalvingGridSearchCV(estimator=ensemble_clf, param_grid=parameters_list,\n",
    "                                   n_jobs=-1, cv=3, verbose=0).fit(feat_train, lab_train)\n",
    "print(\"best param: \", Grid.best_params_)\n",
    "print(\"best score: \", Grid.best_score_)\n",
    "\n",
    "running_secs = (dt.now() - start).seconds\n",
    "print(\"Program running time: \", running_secs)\n",
    "\n",
    "\"\"\"\n",
    "tanh, 0.01, 120, lbfgs\n",
    "tanh, 0.1, 100, lbfgs      20\n",
    "tanh, 0.1, 100,50 , adam\n",
    "tan, .5, 200,100,200, lbfgs\n",
    "tan, 0.1, (60,300,100)adam\n",
    ".05, (300,200,50,300) adam    31%\n",
    "0.02, (60,80,100,120), adam\n",
    "\n",
    "final:\n",
    "mplN = MLPClassifier(batch_size='auto', warm_start=True, max_iter=400, activation = 'tanh', alpha = 0.02, solver = 'adam', hidden_layer_sizes=(60,80,100,120)\n",
    "\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mplA = MLPClassifier(batch_size='auto', warm_start=True, activation = 'tanh', solver='adam', max_iter=400, early_stopping=True, beta_1=0.5)\n",
    "\n",
    "\n",
    "#ensemble_clf = [mplN,mplS,mplA]\n",
    "ensemble_clf = mplA\n",
    "\n",
    "mplAParam = {\n",
    "    'hidden_layer_sizes': [(60,80,100,120),(120,100,80,60)],\n",
    "    'alpha': ( 0.000001, 0.000005),\n",
    "    'beta_2': (0.4,0.5,0.6),\n",
    "}\n",
    "\n",
    "parameters_list = mplAParam\n",
    "start = dt.now()\n",
    "\n",
    "Grid = HalvingGridSearchCV(estimator=ensemble_clf, param_grid=parameters_list,\n",
    "                                   n_jobs=-1, cv=3, verbose=0).fit(feat_train, lab_train)\n",
    "print(\"best param: \", Grid.best_params_)\n",
    "print(\"best score: \", Grid.best_score_)\n",
    "\n",
    "running_secs = (dt.now() - start).seconds\n",
    "print(\"Program running time: \", running_secs)\n",
    "\n",
    "\"\"\"\n",
    "tanh,1e-5,1=.5,2=.7,(150,100,50,10)\n",
    "tan, 5e-6,1=.6,2=.7,(60,300,100)   26%\n",
    "tan, 5e-5, 1=.5, 2=.6, (60,80,100,120)    0.298       614 sec\n",
    "\n",
    "mplA = MLPClassifier(batch_size='auto', warm_start=True, activation = 'tanh', solver='adam', max_iter=400, early_stopping=True, beta_1=0.5, beta_2=0.6,alpha=0.000005, hidden_layer_sizes=(60,80,100,120))\n",
    "\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svcParam = {'C': [15,8,4],\n",
    "            'gamma': [8,5,2],\n",
    "            'kernel': ['rbf', 'linear']\n",
    "            }\n",
    "\n",
    "#ensemble_clf = [mplN,mplS,mplA]\n",
    "ensemble_clf = svc\n",
    "\n",
    "\n",
    "\n",
    "parameters_list = svcParam\n",
    "start = dt.now()\n",
    "\n",
    "Grid = HalvingGridSearchCV(estimator=ensemble_clf, param_grid=parameters_list,\n",
    "                                   n_jobs=-1, cv=3, verbose=0).fit(feat_train, lab_train)\n",
    "print(\"best param: \", Grid.best_params_)\n",
    "print(\"best score: \", Grid.best_score_)\n",
    "\n",
    "running_secs = (dt.now() - start).seconds\n",
    "print(\"Program running time: \", running_secs)\n",
    "\n",
    "\"\"\"\n",
    "3,2,rbf    25%\n",
    "\n",
    "svc = SVC(C=5,gamma=2,kernel='rbf)\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  {'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 12}\n",
      "best score:  0.6133622563361255\n",
      "Program running time:  37\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"\\nrf {'bootstrap': False, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 13, 'warm_start': False}    33%\\n{'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 11} 61% 19 sec\\n{'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 2, 'n_estimators': 12} 61  19 sec\\n\\nfinished\\nrf = RandomForestClassifier(warm_start=False,bootstrap=False, max_depth=16,max_features='auto,min_samples_leaf=2,n_estimators=12)\\n\\n\""
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing cell\n",
    "\n",
    "rf = RandomForestClassifier(warm_start=False,bootstrap=False)\n",
    "ensemble_clf = rf\n",
    "\n",
    "\n",
    "rfParam = {\"max_depth\": range(14, 17, 1), \"min_samples_leaf\": range(2, 4, 1),\n",
    "           \"n_estimators\": range(9, 13, 1),\n",
    "           'max_features': ['auto', 'sqrt']}\n",
    "\n",
    "parameters_list = rfParam\n",
    "start = dt.now()\n",
    "\n",
    "Grid = HalvingGridSearchCV(estimator=ensemble_clf, param_grid=parameters_list,\n",
    "                                   n_jobs=-1, cv=3, verbose=0).fit(feat_train, lab_train)\n",
    "print(\"best param: \", Grid.best_params_)\n",
    "print(\"best score: \", Grid.best_score_)\n",
    "\n",
    "running_secs = (dt.now() - start).seconds\n",
    "print(\"Program running time: \", running_secs)\n",
    "\n",
    "\"\"\"\n",
    "rf {'bootstrap': False, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 13, 'warm_start': False}    33%\n",
    "{'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 11} 61% 19 sec\n",
    "{'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 2, 'n_estimators': 12} 61  19 sec\n",
    "\n",
    "finished\n",
    "rf = RandomForestClassifier(warm_start=False,bootstrap=False, max_depth=16,max_features='auto,min_samples_leaf=2,n_estimators=12)\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc score 2 0.08783321941216678 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lab_pred = Grid.predict(feat_test)\n",
    "print(\"acc score 2\", accuracy_score(lab_test, lab_pred),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc score 2 0.21291866028708134 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(warm_start=False,bootstrap=False, max_depth=16,max_features='auto', min_samples_leaf=2, n_estimators=12)\n",
    "rf.fit(feat_train,lab_train)\n",
    "lab_pred = rf.predict(feat_test)\n",
    "print(\"acc score 2\", accuracy_score(lab_test, lab_pred),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['FL', 'UT', 'FL', ..., 'AK', 'AK', 'AK'], dtype=object)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "9658      CA\n49184     MT\n91271     VA\n36946     MA\n43857     MO\n          ..\n116398    NY\n111585    AK\n100680    AK\n99442     AK\n62886     ND\nName: state, Length: 23408, dtype: object"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param:  {'algorithm': 'auto', 'leaf_size': 9, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 4, 'weights': 'distance'}\n",
      "best score:  0.5624859978140716\n",
      "Program running time:  326\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"\\n{'algorithm': 'brute', 'leaf_size': 11, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 4, 'weights': 'distance'}55%    388\\nkn = KNeighborsClassifier(algorithm='brute',leaf_size=11,metric='euclidean',n_neighbors=5,p=4,weights='distance')\\n\\n\""
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsClassifier(metric = 'euclidean', weights='distance')\n",
    "knParam = {\n",
    "    'n_neighbors': range(5, 7, 1),\n",
    "    'leaf_size': range(9, 11, 1),\n",
    "    'p': (4,5),\n",
    "    'algorithm': ('auto', 'brute','ball_tree')}\n",
    "\n",
    "ensemble_clf = kn\n",
    "parameters_list = knParam\n",
    "start = dt.now()\n",
    "\n",
    "Grid = HalvingGridSearchCV(estimator=ensemble_clf, param_grid=parameters_list,\n",
    "                                   n_jobs=-1, cv=3, verbose=0).fit(feat_train, lab_train)\n",
    "print(\"best param: \", Grid.best_params_)\n",
    "print(\"best score: \", Grid.best_score_)\n",
    "\n",
    "running_secs = (dt.now() - start).seconds\n",
    "print(\"Program running time: \", running_secs)\n",
    "\n",
    "\"\"\"\n",
    "{'algorithm': 'brute', 'leaf_size': 11, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 4, 'weights': 'distance'}55%    388\n",
    "{'algorithm': 'auto', 'leaf_size': 9, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 4, 'weights': 'distance'}\n",
    "kn = KNeighborsClassifier(algorithm='brute',leaf_size=9,metric='euclidean',n_neighbors=7,p=4,weights='distance')\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc score 2 0.025845864661654134 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kn = KNeighborsClassifier(algorithm='brute',leaf_size=11,metric='euclidean',n_neighbors=5,p=4,weights='distance')\n",
    "kn.fit(feat_train,lab_train)\n",
    "lab_pred = kn.predict(feat_test)\n",
    "print(\"acc score 2\", accuracy_score(lab_test, lab_pred),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc score 2 0.0349025974025974 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mplA = MLPClassifier(batch_size='auto', warm_start=True, activation = 'tanh', solver='adam', max_iter=400, early_stopping=True, beta_1=0.5, beta_2=0.6,alpha=0.000005, hidden_layer_sizes=(60,80,100,120))\n",
    "mplA.fit(feat_train,lab_train)\n",
    "lab_pred = mplA.predict(feat_test)\n",
    "print(\"acc score 2\", accuracy_score(lab_test, lab_pred),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "VotingClassifier(estimators=[('mplN',\n                              MLPClassifier(activation='tanh', alpha=0.02,\n                                            hidden_layer_sizes=(60, 80, 100,\n                                                                120),\n                                            max_iter=400, warm_start=True)),\n                             ('mplA',\n                              MLPClassifier(activation='tanh', alpha=5e-06,\n                                            beta_1=0.5, beta_2=0.6,\n                                            early_stopping=True,\n                                            hidden_layer_sizes=(60, 80, 100,\n                                                                120),\n                                            max_iter=400, warm_start=True)),\n                             ('svc', SVC(C=5, gamma=2)),\n                             ('rf',\n                              RandomForestClassifier(bootstrap=False,\n                                                     max_depth=16,\n                                                     min_samples_leaf=2,\n                                                     n_estimators=12)),\n                             ('kn',\n                              KNeighborsClassifier(algorithm='brute',\n                                                   leaf_size=11,\n                                                   metric='euclidean', p=4,\n                                                   weights='distance'))])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "mplN = MLPClassifier(batch_size='auto', warm_start=True, max_iter=400, activation = 'tanh', alpha = 0.02, solver = 'adam', hidden_layer_sizes=(60,80,100,120))\n",
    "mplA = MLPClassifier(batch_size='auto', warm_start=True, activation = 'tanh', solver='adam', max_iter=400, early_stopping=True, beta_1=0.5, beta_2=0.6,alpha=0.000005, hidden_layer_sizes=(60,80,100,120))\n",
    "svc = SVC(C=5,gamma=2,kernel='rbf')\n",
    "rf = RandomForestClassifier(warm_start=False,bootstrap=False, max_depth=16,max_features='auto',min_samples_leaf=2,n_estimators=12)\n",
    "kn = KNeighborsClassifier(algorithm='brute',leaf_size=11,metric='euclidean',n_neighbors=5,p=4,weights='distance')\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('mplN', mplN), ('mplA', mplA), ('svc', svc), ('rf', rf), ('kn', kn)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(feat_train, lab_train)\n",
    "\n",
    "\n",
    "voting_clf2 = VotingClassifier(\n",
    "    estimators=[('mplN', mplN), ('mplA', mplA), ('svc', svc), ('rf', rf), ('kn', kn)],\n",
    "    voting='hard')\n",
    "voting_clf2.fit(feat_train, lab_train)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVC was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc score 2 0.04319036226930964 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nacc score 2    0.04\\n'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#lab_pred = voting_clf.predict(feat_test)\n",
    "#print(\"acc score 1\", accuracy_score(lab_test, lab_pred),\"\\n\")\n",
    "\n",
    "lab_pred = voting_clf2.predict(feat_test)\n",
    "print(\"acc score 2\", accuracy_score(lab_test, lab_pred),\"\\n\")\n",
    "\n",
    "\"\"\"\n",
    "acc score 2    0.04\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}