{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d16ee7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#MultiClass classifier. Predicts one attribute as one of many labels rather than just 2 possible labels.\n",
    "#This assumes there is only one right answer. We could do multilabel classification and present multiple city solutions to the user?\n",
    "#https://scikit-learn.org/stable/modules/multiclass.html    a look at different kinds of models\n",
    "\n",
    "\"\"\" method of going through multiple models\n",
    " https://medium.com/analytics-vidhya/testing-multiple-machine-learning-models-at-once-without-getting-a-headache-5aefb0e7df03    simple good\n",
    " https://github.com/j-planet/machine-learning-big-loop   more advanced, but better. (get parameters.py from this, and the cell for running multiple things\"\"\"\n",
    "\n",
    "\"\"\"https://stackoverflow.com/questions/23045318/grid-search-over-multiple-classifiers\n",
    "Smallest, simple to\n",
    "\n",
    "https://www.codegrepper.com/code-examples/whatever/gridsearchcv+with+multiple+models\n",
    "Straightforward\n",
    "\n",
    "https://www.davidsbatista.net/blog/2018/02/23/model_optimization/\n",
    "Large, hard to understand, but powerful\n",
    "\n",
    "https://github.com/davidsbatista/machine-learning-notebooks/blob/master/hyperparameter-across-models.ipynb\n",
    "Large, hard to understand, but powerful\"\"\"\n",
    "\n",
    "\n",
    "#to do\n",
    "# find best testing method\n",
    "# get best parameters\n",
    "\n",
    "#to ask\n",
    "#why do his cells not work\n",
    "\n",
    "# Import necessary modules from repository\n",
    "from model.data.pipeline import sql_strings as sql, utils as ut\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3031ba1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#dataframe of all monthly data\n",
    "df = ut.load_sql_as_df('SELECT * From MonthlyDataModel;')\n",
    "\n",
    "#dataframe of month averages to fill in bad values\n",
    "monthAvg = ut.load_sql_as_df('SELECT * From MonthlyAverages;')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Getting features and choosing labels. Fill NaN spots with NaN text to manipulate them\n",
    "labels = df[\"state\"]\n",
    "features = df.drop(['region', 'latitude', 'longitude', 'elevation', 'region'], axis=1)\n",
    "features = features.fillna('NaN')\n",
    "\n",
    "# Changing columns in to months to help compare\n",
    "featSer = features[\"month\"].to_numpy()\n",
    "prcpIntM = monthAvg[\"prcpInt\"].to_numpy()\n",
    "prcpFreqM = monthAvg[\"prcpFreq\"].to_numpy()\n",
    "temp_max_normalM = monthAvg[\"temp_max_normal\"].to_numpy()\n",
    "temp_min_normalM = monthAvg[\"temp_min_normal\"].to_numpy()\n",
    "snow_depthM = monthAvg[\"snowInt\"].to_numpy()\n",
    "snow_daysM = monthAvg[\"snowFreq\"].to_numpy()\n",
    "cloudsM = monthAvg[\"clouds\"].to_numpy()\n",
    "dewM = monthAvg[\"dew_point\"].to_numpy()\n",
    "heatM = monthAvg[\"heat_index\"].to_numpy()\n",
    "pressureM = monthAvg[\"pressure\"].to_numpy()\n",
    "windM = monthAvg[\"wind_speed\"].to_numpy()\n",
    "windCalmM = monthAvg[\"wind_calm_percentage\"].to_numpy()\n",
    "\n",
    "prcp_normRay = features[\"prcp_normal\"].to_numpy()\n",
    "prcp_days_tRay = features[\"prcp_days_t\"].to_numpy()\n",
    "temp_max_normalRay = features[\"temp_max_normal\"].to_numpy()\n",
    "temp_min_normalRay = features[\"temp_min_normal\"].to_numpy()\n",
    "snow_depthRay = features[\"snow_depth_days\"].to_numpy()\n",
    "snow_daysRay = features[\"snow_days_t\"].to_numpy()\n",
    "cloudsRay = features[\"clouds\"].to_numpy()\n",
    "dewRay = features[\"dew_point\"].to_numpy()\n",
    "heatRay = features[\"heat_index\"].to_numpy()\n",
    "pressureRay = features[\"pressure\"].to_numpy()\n",
    "windRay = features[\"wind_speed\"].to_numpy()\n",
    "windCalmRay = features[\"wind_calm_percentage\"].to_numpy()\n",
    "\n",
    "#replacing bad values\n",
    "for i in range(len(featSer)):\n",
    "    if prcp_normRay[i] == 'NaN' or prcp_normRay[i] == -9999 or prcp_normRay[i] == -8888 or prcp_normRay[i] == -7777 or prcp_normRay[i] == -6666 or prcp_normRay[i] == -5555:\n",
    "        prcp_normRay[i] = prcpIntM[featSer[i]-1]\n",
    "    if prcp_days_tRay[i] == 'NaN' or prcp_days_tRay[i] == -9999 or prcp_days_tRay[i] == -8888 or prcp_days_tRay[i] == -7777 or prcp_days_tRay[i] == -6666 or prcp_days_tRay[i] == -5555:\n",
    "        prcp_days_tRay[i] = prcpFreqM[featSer[i]-1]\n",
    "    if temp_max_normalRay[i] == 'NaN' or temp_max_normalRay[i] == -9999 or temp_max_normalRay[i] == -8888 or temp_max_normalRay[i] == -7777 or temp_max_normalRay[i] == -6666 or temp_max_normalRay[i] == -5555:\n",
    "        temp_max_normalRay[i] = temp_max_normalM[featSer[i]-1]\n",
    "    if temp_min_normalRay[i] == 'NaN' or temp_min_normalRay[i] == -9999 or temp_min_normalRay[i] == -8888 or temp_min_normalRay[i] == -7777 or temp_min_normalRay[i] == -6666 or temp_min_normalRay[i] == -5555:\n",
    "        temp_min_normalRay[i] = temp_min_normalM[featSer[i]-1]\n",
    "    if snow_depthRay[i] == 'NaN' or snow_depthRay[i] == -9999 or snow_depthRay[i] == -8888 or snow_depthRay[i] == -7777 or snow_depthRay[i] == -6666 or snow_depthRay[i] == -5555:\n",
    "        snow_depthRay[i] = snow_depthM[featSer[i]-1]\n",
    "    if snow_daysRay[i] == 'NaN' or snow_daysRay[i] == -9999 or snow_daysRay[i] == -8888 or snow_daysRay[i] == -7777 or snow_daysRay[i] == -6666 or snow_daysRay[i] == -5555:\n",
    "        snow_daysRay[i] = snow_daysM[featSer[i]-1]\n",
    "    if cloudsRay[i] == 'NaN' or cloudsRay[i] == -9999 or cloudsRay[i] == -8888 or cloudsRay[i] == -7777 or cloudsRay[i] == -6666 or cloudsRay[i] == -5555:\n",
    "        cloudsRay[i] = cloudsM[featSer[i]-1]\n",
    "    if dewRay[i] == 'NaN' or dewRay[i] == -9999 or dewRay[i] == -8888 or dewRay[i] == -7777 or dewRay[i] == -6666 or dewRay[i] == -5555:\n",
    "        dewRay[i] = dewM[featSer[i]-1]\n",
    "    if heatRay[i] == 'NaN' or heatRay[i] == -9999 or heatRay[i] == -8888 or heatRay[i] == -7777 or heatRay[i] == -6666 or heatRay[i] == -5555:\n",
    "        heatRay[i] = heatM[featSer[i]-1]\n",
    "    if pressureRay[i] == 'NaN' or pressureRay[i] == -9999 or pressureRay[i] == -8888 or pressureRay[i] == -7777 or pressureRay[i] == -6666 or pressureRay[i] == -5555:\n",
    "        pressureRay[i] = pressureM[featSer[i]-1]\n",
    "    if windRay[i] == 'NaN' or windRay[i] == -9999 or windRay[i] == -8888 or windRay[i] == -7777 or windRay[i] == -6666 or windRay[i] == -5555:\n",
    "        windRay[i] = windM[featSer[i]-1]\n",
    "    if windCalmRay[i] == 'NaN' or windCalmRay[i] == -9999 or windCalmRay[i] == -8888 or windCalmRay[i] == -7777 or windCalmRay[i] == -6666 or windCalmRay[i] == -5555:\n",
    "        windCalmRay[i] = windCalmM[featSer[i]-1]\n",
    "\n",
    "\n",
    "# Recreating filled dataset\n",
    "features = pd.DataFrame({'prcp_normRay' : prcp_normRay, 'prcp_days_tRay' : prcp_days_tRay, \"temp_max_normalRay\" : temp_max_normalRay, \"temp_min_normalRay\" : temp_min_normalRay, \"snow_depthRay\" : snow_depthRay, \"snow_daysRay\" : snow_daysRay, \"cloudsRay\" : cloudsRay, \"dewRay\" : dewRay, \"heatRay\" : heatRay, \"pressureRay\" : pressureRay, \"windRay\" : windRay, \"windCalmRay\" : windCalmRay})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       prcp_normRay prcp_days_tRay temp_max_normalRay temp_min_normalRay  \\\n0               5.3           69.0          41.924644          21.303576   \n1              5.07           65.0          45.985372          24.106816   \n2               5.8           62.0          54.495133          31.252366   \n3              3.77           48.0          64.407005          39.586609   \n4              3.82           48.0          73.406937           48.77541   \n...             ...            ...                ...                ...   \n117031         3.22      25.909684               85.4               62.7   \n117032         3.04      46.810539               77.8               53.6   \n117033         2.04      47.409751               65.2               40.6   \n117034         1.41      49.541899               49.7               28.0   \n117035         0.93      50.036534               36.9               17.1   \n\n       snow_depthRay snow_daysRay  cloudsRay     dewRay    heatRay  \\\n0                0.0          0.0  55.667977  26.341895  35.417982   \n1                0.0          0.0  55.013862  28.228661  38.559721   \n2         -309.95931  -297.336583  52.051446  33.052022  45.700434   \n3                0.0          0.0  49.932187   39.67777  54.337107   \n4                0.0          0.0  48.941521  48.669454    63.3096   \n...              ...          ...        ...        ...        ...   \n117031     -6.026158   -32.307496  40.020323  59.955251  74.535821   \n117032   -156.429374  -337.711363  41.015647  53.890063  67.271141   \n117033   -553.695795  -656.829311  45.018233   44.25134  56.376711   \n117034   -244.419299  -363.569282   51.45818  35.445112  45.895488   \n117035   -238.601821  -291.094614  55.725457   28.84527  37.656348   \n\n        pressureRay   windRay windCalmRay  \n0       1018.967064  8.593669    14.68457  \n1       1018.084567  8.813964   13.644477  \n2        1016.38444  9.329369   11.746978  \n3       1014.836497  9.386922    11.09783  \n4        1014.35943  8.659783   12.057727  \n...             ...       ...         ...  \n117031   1015.39399  7.050787   16.593875  \n117032  1015.676289  7.402396   16.429875  \n117033   1016.88648  7.768246   16.520839  \n117034  1017.744118  8.266765   15.842452  \n117035  1018.840951  8.419217   15.283866  \n\n[117036 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prcp_normRay</th>\n      <th>prcp_days_tRay</th>\n      <th>temp_max_normalRay</th>\n      <th>temp_min_normalRay</th>\n      <th>snow_depthRay</th>\n      <th>snow_daysRay</th>\n      <th>cloudsRay</th>\n      <th>dewRay</th>\n      <th>heatRay</th>\n      <th>pressureRay</th>\n      <th>windRay</th>\n      <th>windCalmRay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.3</td>\n      <td>69.0</td>\n      <td>41.924644</td>\n      <td>21.303576</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55.667977</td>\n      <td>26.341895</td>\n      <td>35.417982</td>\n      <td>1018.967064</td>\n      <td>8.593669</td>\n      <td>14.68457</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.07</td>\n      <td>65.0</td>\n      <td>45.985372</td>\n      <td>24.106816</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55.013862</td>\n      <td>28.228661</td>\n      <td>38.559721</td>\n      <td>1018.084567</td>\n      <td>8.813964</td>\n      <td>13.644477</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.8</td>\n      <td>62.0</td>\n      <td>54.495133</td>\n      <td>31.252366</td>\n      <td>-309.95931</td>\n      <td>-297.336583</td>\n      <td>52.051446</td>\n      <td>33.052022</td>\n      <td>45.700434</td>\n      <td>1016.38444</td>\n      <td>9.329369</td>\n      <td>11.746978</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.77</td>\n      <td>48.0</td>\n      <td>64.407005</td>\n      <td>39.586609</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>49.932187</td>\n      <td>39.67777</td>\n      <td>54.337107</td>\n      <td>1014.836497</td>\n      <td>9.386922</td>\n      <td>11.09783</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.82</td>\n      <td>48.0</td>\n      <td>73.406937</td>\n      <td>48.77541</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48.941521</td>\n      <td>48.669454</td>\n      <td>63.3096</td>\n      <td>1014.35943</td>\n      <td>8.659783</td>\n      <td>12.057727</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>117031</th>\n      <td>3.22</td>\n      <td>25.909684</td>\n      <td>85.4</td>\n      <td>62.7</td>\n      <td>-6.026158</td>\n      <td>-32.307496</td>\n      <td>40.020323</td>\n      <td>59.955251</td>\n      <td>74.535821</td>\n      <td>1015.39399</td>\n      <td>7.050787</td>\n      <td>16.593875</td>\n    </tr>\n    <tr>\n      <th>117032</th>\n      <td>3.04</td>\n      <td>46.810539</td>\n      <td>77.8</td>\n      <td>53.6</td>\n      <td>-156.429374</td>\n      <td>-337.711363</td>\n      <td>41.015647</td>\n      <td>53.890063</td>\n      <td>67.271141</td>\n      <td>1015.676289</td>\n      <td>7.402396</td>\n      <td>16.429875</td>\n    </tr>\n    <tr>\n      <th>117033</th>\n      <td>2.04</td>\n      <td>47.409751</td>\n      <td>65.2</td>\n      <td>40.6</td>\n      <td>-553.695795</td>\n      <td>-656.829311</td>\n      <td>45.018233</td>\n      <td>44.25134</td>\n      <td>56.376711</td>\n      <td>1016.88648</td>\n      <td>7.768246</td>\n      <td>16.520839</td>\n    </tr>\n    <tr>\n      <th>117034</th>\n      <td>1.41</td>\n      <td>49.541899</td>\n      <td>49.7</td>\n      <td>28.0</td>\n      <td>-244.419299</td>\n      <td>-363.569282</td>\n      <td>51.45818</td>\n      <td>35.445112</td>\n      <td>45.895488</td>\n      <td>1017.744118</td>\n      <td>8.266765</td>\n      <td>15.842452</td>\n    </tr>\n    <tr>\n      <th>117035</th>\n      <td>0.93</td>\n      <td>50.036534</td>\n      <td>36.9</td>\n      <td>17.1</td>\n      <td>-238.601821</td>\n      <td>-291.094614</td>\n      <td>55.725457</td>\n      <td>28.84527</td>\n      <td>37.656348</td>\n      <td>1018.840951</td>\n      <td>8.419217</td>\n      <td>15.283866</td>\n    </tr>\n  </tbody>\n</table>\n<p>117036 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.91110925,  0.82029827, -1.25013457, ...,  1.49970583,\n         0.37076481,  0.12042121],\n       [ 0.82387832,  0.64962544, -1.02606424, ...,  0.99407173,\n         0.61304703, -0.24700796],\n       [ 1.10074171,  0.52162081, -0.55649706, ...,  0.01996877,\n         1.17989276, -0.9173286 ],\n       ...,\n       [-0.32529439, -0.10091895,  0.03419572, ...,  0.30761668,\n        -0.53704064,  0.76911125],\n       [-0.56423129, -0.00994405, -0.8210917 , ...,  0.79900818,\n         0.01123386,  0.52946061],\n       [-0.74627845,  0.01116116, -1.52739358, ...,  1.42744863,\n         0.17890146,  0.33213148]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Scalling all data\n",
    "scaler = StandardScaler()\n",
    "featPrepped = scaler.fit_transform(features)\n",
    "featPrepped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feat_train, feat_test, lab_train, lab_test = train_test_split(featPrepped, labels, random_state=42)\n",
    "# stratify by city for separating training and testing. stratified sampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4152226665299566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(feat_train, lab_train)\n",
    "\n",
    "print(clf.score(feat_test, lab_test))  #This automatically makes predictions on feat_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4355817b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Next 3 cells are simons and do not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'numpy.ndarray' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m predictions_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(df)):\n\u001B[1;32m----> 8\u001B[0m     row \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msort_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43mascending\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m[:TOP]\n\u001B[0;32m      9\u001B[0m     rowDf \u001B[38;5;241m=\u001B[39m row\u001B[38;5;241m.\u001B[39mto_frame()\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m#print([[CITIES[int(x[0])], x[1]] for x in rowDf.to_numpy()])\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\ml-team3\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\ml-team3\\venv\\lib\\site-packages\\pandas\\core\\series.py:3526\u001B[0m, in \u001B[0;36mSeries.sort_values\u001B[1;34m(self, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001B[0m\n\u001B[0;32m   3524\u001B[0m \u001B[38;5;66;03m# GH 35922. Make sorting stable by leveraging nargsort\u001B[39;00m\n\u001B[0;32m   3525\u001B[0m values_to_sort \u001B[38;5;241m=\u001B[39m ensure_key_mapped(\u001B[38;5;28mself\u001B[39m, key)\u001B[38;5;241m.\u001B[39m_values \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m-> 3526\u001B[0m sorted_index \u001B[38;5;241m=\u001B[39m \u001B[43mnargsort\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues_to_sort\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkind\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mbool\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mascending\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_position\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3528\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(\n\u001B[0;32m   3529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[sorted_index], index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex[sorted_index]\n\u001B[0;32m   3530\u001B[0m )\n\u001B[0;32m   3532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ignore_index:\n",
      "File \u001B[1;32m~\\Documents\\ml-team3\\venv\\lib\\site-packages\\pandas\\core\\sorting.py:417\u001B[0m, in \u001B[0;36mnargsort\u001B[1;34m(items, kind, ascending, na_position, key, mask)\u001B[0m\n\u001B[0;32m    415\u001B[0m     non_nans \u001B[38;5;241m=\u001B[39m non_nans[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    416\u001B[0m     non_nan_idx \u001B[38;5;241m=\u001B[39m non_nan_idx[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m--> 417\u001B[0m indexer \u001B[38;5;241m=\u001B[39m non_nan_idx[\u001B[43mnon_nans\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margsort\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkind\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkind\u001B[49m\u001B[43m)\u001B[49m]\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ascending:\n\u001B[0;32m    419\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[1;31mTypeError\u001B[0m: '>' not supported between instances of 'numpy.ndarray' and 'str'"
     ]
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "TOP = 5\n",
    "TMP = 62\n",
    "CITIES = labels.unique()\n",
    "\n",
    "predictions_list = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i].sort_values(ascending=False)[:TOP]\n",
    "    rowDf = row.to_frame().reset_index()\n",
    "    #print([[CITIES[int(x[0])], x[1]] for x in rowDf.to_numpy()])\n",
    "    vals = np.insert(np.array([[CITIES[int(x[0])], x[1]] for x in rowDf.to_numpy()]), 0, lab_test.iloc[i])\n",
    "    predictions_list.append(vals)\n",
    "\n",
    "cols = ['true']\n",
    "for i in range(TOP):\n",
    "    cols.append('city{x}'.format(x=i + 1))\n",
    "    cols.append('prob{x}'.format(x=i + 1))\n",
    "\n",
    "preds = pd.DataFrame(predictions_list,\n",
    "                     columns=cols)\n",
    "preds\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"count = 0\n",
    "for i in range(len(preds)):\n",
    "    if preds.iloc[i]['true'] == preds.iloc[i]['city1']:\n",
    "        count += 1\n",
    "        #print('{i}: {t} and {p}'.format(i=i, t=preds['true'][i], p=preds['city1'][i]))\n",
    "\n",
    "print('Accuracy: {r}/{t}, {p}%'.format(r=count, t=len(preds), p=round(100*count/len(preds))))\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"CITY = 'Denver'\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    row = preds.iloc[i]\n",
    "    if row['true'] == CITY and row['city1'] != CITY:\n",
    "        print(row['city1'])\n",
    "CITIES\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a15a761",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "656fd4f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bf397da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading models...:  75%|███████▌  | 3/4 [00:53<00:17, 17.93s/it]C:\\Users\\Trent\\Documents\\ml-team3\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Reading models...: 100%|██████████| 4/4 [03:30<00:00, 52.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest 0.4154960866741857\n",
      "ExtraTreeClf 0.40698588468505414\n",
      "NN MPL 0.3758501657609624\n",
      "decision tree 0.3188762432072183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "log_reg_params = [{\"C\": 0.01}, {\"C\": 0.1}, {\"C\": 1}, {\"C\": 10}]\n",
    "dec_tree_params = [{\"criterion\": \"gini\"}, {\"criterion\": \"entropy\"}]\n",
    "rand_for_params = [{\"criterion\": \"gini\"}, {\"criterion\": \"entropy\"}]\n",
    "kneighbors_params = [{\"n_neighbors\": 3}, {\"n_neighbors\": 5}]\n",
    "naive_bayes_params = [{}]\n",
    "svc_params = [{\"C\": 0.01}, {\"C\": 0.1}, {\"C\": 1}, {\"C\": 10}]\n",
    "\n",
    "modelclasses = [\n",
    "    #[\"GradientBoostingClf\", GradientBoostingClassifier()],\n",
    "    [\"ExtraTreeClf\", ExtraTreesClassifier()],\n",
    "    [\"decision tree\", DecisionTreeClassifier()],\n",
    "    [\"random forest\", RandomForestClassifier()],\n",
    "    #[\"k neighbors\", KNeighborsClassifier()],\n",
    "    #[\"NearestCentroid\", NearestCentroid()],\n",
    "    #[\"RadiusNeighbor\", RadiusNeighborsClassifier()],\n",
    "    #[\"GaussianProcess\", GaussianProcessClassifier()],\n",
    "    #[\"naive bayes Gaussian NB\", GaussianNB()],\n",
    "    #[\"naive bayes Bernoulli NB\", BernoulliNB()],\n",
    "    #[\"support vector machines\", SVC()],\n",
    "    #[\"Nu support vector machines\", NuSVC()],\n",
    "    [\"NN MPL\", MLPClassifier()]\n",
    "]\n",
    "\n",
    "progress_bar = tqdm(total=len(modelclasses), desc='Reading models...')\n",
    "\n",
    "insights = []\n",
    "for modelname, model in modelclasses:\n",
    "    try:\n",
    "        model.fit(feat_train, lab_train)\n",
    "        score = model.score(feat_test, lab_test)\n",
    "        insights.append((modelname, model, score))\n",
    "    except:\n",
    "        print(modelname, \" did not work \\n\")\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "\n",
    "insights.sort(key=lambda x: x[-1], reverse=True)\n",
    "for modelname, model, score in insights:\n",
    "    print(modelname, score)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4423fd9a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef48f30a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afaa8d6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading models...:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading models...:  50%|█████     | 1/2 [01:34<01:34, 94.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 15, 'min_samples_leaf': 1, 'n_estimators': 101}\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading models...: 100%|██████████| 2/2 [03:41<00:00, 110.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 25, 'min_samples_leaf': 1, 'n_estimators': 101}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "rf=RandomForestClassifier(random_state=4, n_jobs=-1, max_features=\"auto\", warm_start=True)\n",
    "ex=ExtraTreesClassifier(random_state=4, n_jobs=-1, max_features=\"auto\", warm_start=True)\n",
    "\n",
    "ensemble_clf=[rf, ex]\n",
    "\n",
    "params1={\"max_depth\": range(5,30,10), \"min_samples_leaf\": range(1,30,10),\n",
    "         \"n_estimators\":range(1,200,100)}\n",
    "params2={\"criterion\":[\"gini\", \"entropy\"],\"max_depth\": range(5,30,10),\n",
    "         \"min_samples_leaf\": range(1,30,10), \"n_estimators\":range(1,200,100)}\n",
    "\n",
    "parameters_list=[params1, params2]\n",
    "\n",
    "model_log=[\"_rf\", \"_ex\"]\n",
    "\n",
    "progress_bar = tqdm(total=len(ensemble_clf), desc='Reading models...')\n",
    "\n",
    "Grid = []\n",
    "\n",
    "for i in range(len(ensemble_clf)):\n",
    "    try:\n",
    "        Grid=GridSearchCV(estimator=ensemble_clf[i], param_grid=parameters_list[i],\n",
    "                      n_jobs=-1, cv=3, verbose=3).fit(feat_train, lab_train)\n",
    "    #globals()['Grid%s' % model_log[i]]=pd.DataFrame(Grid.cv_results_)\n",
    "        print(Grid.best_params_)\n",
    "    except:\n",
    "        print(\"model \", i, \"did not work\")\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}