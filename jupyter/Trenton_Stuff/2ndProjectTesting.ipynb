{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d16ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MultiClass classifier. Predicts one attribute as one of many labels rather than just 2 possible labels.\n",
    "#This assumes there is only one right answer. We could do multilabel classification and present multiple city solutions to the user?\n",
    "#https://scikit-learn.org/stable/modules/multiclass.html    a look at different kinds of models\n",
    "\n",
    "\"\"\" method of going through multiple models\n",
    " https://medium.com/analytics-vidhya/testing-multiple-machine-learning-models-at-once-without-getting-a-headache-5aefb0e7df03    simple good\n",
    " https://github.com/j-planet/machine-learning-big-loop   more advanced, but better. (get parameters.py from this, and the cell for running multiple things\"\"\"\n",
    "\n",
    "\"\"\"https://stackoverflow.com/questions/23045318/grid-search-over-multiple-classifiers\n",
    "Smallest, simple to\n",
    "\n",
    "https://www.codegrepper.com/code-examples/whatever/gridsearchcv+with+multiple+models\n",
    "Straightforward\n",
    "\n",
    "https://www.davidsbatista.net/blog/2018/02/23/model_optimization/\n",
    "Large, hard to understand, but powerful\n",
    "\n",
    "https://github.com/davidsbatista/machine-learning-notebooks/blob/master/hyperparameter-across-models.ipynb\n",
    "Large, hard to understand, but powerful\"\"\"\n",
    "\n",
    "\n",
    "#to do\n",
    "# find best testing method\n",
    "# get best parameters\n",
    "\n",
    "#to ask\n",
    "#why do his cells not work\n",
    "\n",
    "# Import necessary modules from repository\n",
    "from model.data.pipeline import sql_strings as sql, utils as ut\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3031ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe of all monthly data\n",
    "df = ut.load_sql_as_df('SELECT * From MonthlyDataModel;')\n",
    "\n",
    "#dataframe of month averages to fill in bad values\n",
    "monthAvg = ut.load_sql_as_df('SELECT * From MonthlyAverages;')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Getting features and choosing labels. Fill NaN spots with NaN text to manipulate them\n",
    "labels = df[\"state\"]\n",
    "features = df.drop(['region', 'latitude', 'longitude', 'elevation', 'region'], axis=1)\n",
    "features = features.fillna('NaN')\n",
    "\n",
    "# Changing columns in to months to help compare\n",
    "featSer = features[\"month\"].to_numpy()\n",
    "prcpIntM = monthAvg[\"prcpInt\"].to_numpy()\n",
    "prcpFreqM = monthAvg[\"prcpFreq\"].to_numpy()\n",
    "temp_max_normalM = monthAvg[\"temp_max_normal\"].to_numpy()\n",
    "temp_min_normalM = monthAvg[\"temp_min_normal\"].to_numpy()\n",
    "snow_depthM = monthAvg[\"snowInt\"].to_numpy()\n",
    "snow_daysM = monthAvg[\"snowFreq\"].to_numpy()\n",
    "cloudsM = monthAvg[\"clouds\"].to_numpy()\n",
    "\n",
    "prcp_normRay = features[\"prcp_normal\"].to_numpy()\n",
    "prcp_days_tRay = features[\"prcp_days_t\"].to_numpy()\n",
    "temp_max_normalRay = features[\"temp_max_normal\"].to_numpy()\n",
    "temp_min_normalRay = features[\"temp_min_normal\"].to_numpy()\n",
    "snow_depthRay = features[\"snow_depth_days\"].to_numpy()\n",
    "snow_daysRay = features[\"snow_days_t\"].to_numpy()\n",
    "cloudsRay = features[\"clouds\"].to_numpy()\n",
    "\n",
    "#replacing bad values\n",
    "for i in range(len(featSer)):\n",
    "    if prcp_normRay[i] == 'NaN' or prcp_normRay[i] == -9999 or prcp_normRay[i] == -8888 or prcp_normRay[i] == -7777 or prcp_normRay[i] == -6666 or prcp_normRay[i] == -5555:\n",
    "        prcp_normRay[i] = prcpIntM[featSer[i]-1]\n",
    "    if prcp_days_tRay[i] == 'NaN' or prcp_days_tRay[i] == -9999 or prcp_days_tRay[i] == -8888 or prcp_days_tRay[i] == -7777 or prcp_days_tRay[i] == -6666 or prcp_days_tRay[i] == -5555:\n",
    "        prcp_days_tRay[i] = prcpFreqM[featSer[i]-1]\n",
    "    if temp_max_normalRay[i] == 'NaN' or temp_max_normalRay[i] == -9999 or temp_max_normalRay[i] == -8888 or temp_max_normalRay[i] == -7777 or temp_max_normalRay[i] == -6666 or temp_max_normalRay[i] == -5555:\n",
    "        temp_max_normalRay[i] = temp_max_normalM[featSer[i]-1]\n",
    "    if temp_min_normalRay[i] == 'NaN' or temp_min_normalRay[i] == -9999 or temp_min_normalRay[i] == -8888 or temp_min_normalRay[i] == -7777 or temp_min_normalRay[i] == -6666 or temp_min_normalRay[i] == -5555:\n",
    "        temp_min_normalRay[i] = temp_min_normalM[featSer[i]-1]\n",
    "    if snow_depthRay[i] == 'NaN' or snow_depthRay[i] == -9999 or snow_depthRay[i] == -8888 or snow_depthRay[i] == -7777 or snow_depthRay[i] == -6666 or snow_depthRay[i] == -5555:\n",
    "        snow_depthRay[i] = snow_depthM[featSer[i]-1]\n",
    "    if snow_daysRay[i] == 'NaN' or snow_daysRay[i] == -9999 or snow_daysRay[i] == -8888 or snow_daysRay[i] == -7777 or snow_daysRay[i] == -6666 or snow_daysRay[i] == -5555:\n",
    "        snow_daysRay[i] = snow_daysM[featSer[i]-1]\n",
    "    if cloudsRay[i] == 'NaN' or cloudsRay[i] == -9999 or cloudsRay[i] == -8888 or cloudsRay[i] == -7777 or cloudsRay[i] == -6666 or cloudsRay[i] == -5555:\n",
    "        cloudsRay[i] = cloudsM[featSer[i]-1]\n",
    "\n",
    "# Recreating filled dataset\n",
    "features = pd.DataFrame({'prcp_normRay' : prcp_normRay, 'prcp_days_tRay' : prcp_days_tRay, \"temp_max_normalRay\" : temp_max_normalRay, \"temp_min_normalRay\" : temp_min_normalRay, \"snow_depthRay\" : snow_depthRay, \"snow_daysRay\" : snow_daysRay, \"cloudsRay\" : cloudsRay})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       prcp_normRay prcp_days_tRay temp_max_normalRay temp_min_normalRay  \\\n0               5.3           69.0          41.924644          21.303576   \n1              5.07           65.0          45.985372          24.106816   \n2               5.8           62.0          54.495133          31.252366   \n3              3.77           48.0          64.407005          39.586609   \n4              3.82           48.0          73.406937           48.77541   \n...             ...            ...                ...                ...   \n117022         3.22      25.909684               85.4               62.7   \n117023         3.04      46.810539               77.8               53.6   \n117024         2.04      47.409751               65.2               40.6   \n117025         1.41      49.541899               49.7               28.0   \n117026         0.93      50.036534               36.9               17.1   \n\n       snow_depthRay snow_daysRay  cloudsRay  \n0                0.0          0.0  55.667977  \n1                0.0          0.0  55.013862  \n2         -309.95931  -297.336583  52.051446  \n3                0.0          0.0  49.932187  \n4                0.0          0.0  48.941521  \n...              ...          ...        ...  \n117022     -6.026158   -32.307496  40.020323  \n117023   -156.429374  -337.711363  41.015647  \n117024   -553.695795  -656.829311  45.018233  \n117025   -244.419299  -363.569282   51.45818  \n117026   -238.601821  -291.094614  55.725457  \n\n[117027 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prcp_normRay</th>\n      <th>prcp_days_tRay</th>\n      <th>temp_max_normalRay</th>\n      <th>temp_min_normalRay</th>\n      <th>snow_depthRay</th>\n      <th>snow_daysRay</th>\n      <th>cloudsRay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.3</td>\n      <td>69.0</td>\n      <td>41.924644</td>\n      <td>21.303576</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55.667977</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.07</td>\n      <td>65.0</td>\n      <td>45.985372</td>\n      <td>24.106816</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55.013862</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.8</td>\n      <td>62.0</td>\n      <td>54.495133</td>\n      <td>31.252366</td>\n      <td>-309.95931</td>\n      <td>-297.336583</td>\n      <td>52.051446</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.77</td>\n      <td>48.0</td>\n      <td>64.407005</td>\n      <td>39.586609</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>49.932187</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.82</td>\n      <td>48.0</td>\n      <td>73.406937</td>\n      <td>48.77541</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48.941521</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>117022</th>\n      <td>3.22</td>\n      <td>25.909684</td>\n      <td>85.4</td>\n      <td>62.7</td>\n      <td>-6.026158</td>\n      <td>-32.307496</td>\n      <td>40.020323</td>\n    </tr>\n    <tr>\n      <th>117023</th>\n      <td>3.04</td>\n      <td>46.810539</td>\n      <td>77.8</td>\n      <td>53.6</td>\n      <td>-156.429374</td>\n      <td>-337.711363</td>\n      <td>41.015647</td>\n    </tr>\n    <tr>\n      <th>117024</th>\n      <td>2.04</td>\n      <td>47.409751</td>\n      <td>65.2</td>\n      <td>40.6</td>\n      <td>-553.695795</td>\n      <td>-656.829311</td>\n      <td>45.018233</td>\n    </tr>\n    <tr>\n      <th>117025</th>\n      <td>1.41</td>\n      <td>49.541899</td>\n      <td>49.7</td>\n      <td>28.0</td>\n      <td>-244.419299</td>\n      <td>-363.569282</td>\n      <td>51.45818</td>\n    </tr>\n    <tr>\n      <th>117026</th>\n      <td>0.93</td>\n      <td>50.036534</td>\n      <td>36.9</td>\n      <td>17.1</td>\n      <td>-238.601821</td>\n      <td>-291.094614</td>\n      <td>55.725457</td>\n    </tr>\n  </tbody>\n</table>\n<p>117027 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.91107733,  0.82026143, -1.25009436, ...,  0.54633954,\n         0.56557525,  1.15810527],\n       [ 0.82384972,  0.64959163, -1.02602689, ...,  0.54633954,\n         0.56557525,  1.0542527 ],\n       [ 1.10070256,  0.52158929, -0.55646573, ..., -1.26585409,\n        -1.02904868,  0.58391578],\n       ...,\n       [-0.3252792 , -0.1009394 ,  0.03421949, ..., -2.69087244,\n        -2.95701765, -0.53273362],\n       [-0.564207  , -0.00996612, -0.82105698, ..., -0.88267092,\n        -1.38425639,  0.48972407],\n       [-0.74624723,  0.01113871, -1.52734981, ..., -0.84865873,\n        -0.99557283,  1.16723128]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Scalling all data\n",
    "scaler = StandardScaler()\n",
    "featPrepped = scaler.fit_transform(features)\n",
    "featPrepped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feat_train, feat_test, lab_train, lab_test = train_test_split(featPrepped, labels, random_state=42)\n",
    "# stratify by city for separating training and testing. stratified sampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40855179956933385\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(feat_train, lab_train)\n",
    "\n",
    "print(clf.score(feat_test, lab_test))  #This automatically makes predictions on feat_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4355817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Next 3 cells are simons and do not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'numpy.ndarray' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9796\\4013639378.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mpredictions_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m     \u001B[0mrow\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort_values\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mascending\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mTOP\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m     \u001B[0mrowDf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_frame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreset_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[1;31m#print([[CITIES[int(x[0])], x[1]] for x in rowDf.to_numpy()])\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\trenton\\documents\\programming\\ml-team3\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\trenton\\documents\\programming\\ml-team3\\venv\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36msort_values\u001B[1;34m(self, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001B[0m\n\u001B[0;32m   3453\u001B[0m         \u001B[1;31m# GH 35922. Make sorting stable by leveraging nargsort\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3454\u001B[0m         \u001B[0mvalues_to_sort\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mensure_key_mapped\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3455\u001B[1;33m         \u001B[0msorted_index\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnargsort\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues_to_sort\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkind\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbool\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mascending\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mna_position\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3456\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3457\u001B[0m         result = self._constructor(\n",
      "\u001B[1;32mc:\\users\\trenton\\documents\\programming\\ml-team3\\venv\\lib\\site-packages\\pandas\\core\\sorting.py\u001B[0m in \u001B[0;36mnargsort\u001B[1;34m(items, kind, ascending, na_position, key, mask)\u001B[0m\n\u001B[0;32m    401\u001B[0m         \u001B[0mnon_nans\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnon_nans\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    402\u001B[0m         \u001B[0mnon_nan_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnon_nan_idx\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 403\u001B[1;33m     \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnon_nan_idx\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnon_nans\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margsort\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkind\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkind\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    404\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mascending\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    405\u001B[0m         \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mindexer\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: '>' not supported between instances of 'numpy.ndarray' and 'str'"
     ]
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "TOP = 5\n",
    "TMP = 62\n",
    "CITIES = labels.unique()\n",
    "\n",
    "predictions_list = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i].sort_values(ascending=False)[:TOP]\n",
    "    rowDf = row.to_frame().reset_index()\n",
    "    #print([[CITIES[int(x[0])], x[1]] for x in rowDf.to_numpy()])\n",
    "    vals = np.insert(np.array([[CITIES[int(x[0])], x[1]] for x in rowDf.to_numpy()]), 0, lab_test.iloc[i])\n",
    "    predictions_list.append(vals)\n",
    "\n",
    "cols = ['true']\n",
    "for i in range(TOP):\n",
    "    cols.append('city{x}'.format(x=i + 1))\n",
    "    cols.append('prob{x}'.format(x=i + 1))\n",
    "\n",
    "preds = pd.DataFrame(predictions_list,\n",
    "                     columns=cols)\n",
    "preds\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"count = 0\n",
    "for i in range(len(preds)):\n",
    "    if preds.iloc[i]['true'] == preds.iloc[i]['city1']:\n",
    "        count += 1\n",
    "        #print('{i}: {t} and {p}'.format(i=i, t=preds['true'][i], p=preds['city1'][i]))\n",
    "\n",
    "print('Accuracy: {r}/{t}, {p}%'.format(r=count, t=len(preds), p=round(100*count/len(preds))))\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"CITY = 'Denver'\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    row = preds.iloc[i]\n",
    "    if row['true'] == CITY and row['city1'] != CITY:\n",
    "        print(row['city1'])\n",
    "CITIES\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a15a761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "656fd4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bf397da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcess  did not work \n",
      "\n",
      "Nu support vector machines  did not work \n",
      "\n",
      "random forest 0.40834672044297093\n",
      "ExtraTreeClf 0.40028027480602935\n",
      "k neighbors 0.361349420651468\n",
      "NN MPL 0.337765321119732\n",
      "GradientBoostingClf 0.33509929247701403\n",
      "decision tree 0.3122329698875483\n",
      "support vector machines 0.29975732303380387\n",
      "naive bayes Gaussian NB 0.1117339440133985\n",
      "naive bayes Bernoulli NB 0.07755408961957821\n",
      "NearestCentroid 0.06360870902689955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\trenton\\documents\\programming\\ml-team3\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "\n",
    "log_reg_params = [{\"C\": 0.01}, {\"C\": 0.1}, {\"C\": 1}, {\"C\": 10}]\n",
    "dec_tree_params = [{\"criterion\": \"gini\"}, {\"criterion\": \"entropy\"}]\n",
    "rand_for_params = [{\"criterion\": \"gini\"}, {\"criterion\": \"entropy\"}]\n",
    "kneighbors_params = [{\"n_neighbors\": 3}, {\"n_neighbors\": 5}]\n",
    "naive_bayes_params = [{}]\n",
    "svc_params = [{\"C\": 0.01}, {\"C\": 0.1}, {\"C\": 1}, {\"C\": 10}]\n",
    "\n",
    "modelclasses = [\n",
    "    [\"GradientBoostingClf\", GradientBoostingClassifier()],\n",
    "    [\"ExtraTreeClf\", ExtraTreesClassifier()],\n",
    "    [\"decision tree\", DecisionTreeClassifier()],\n",
    "    [\"random forest\", RandomForestClassifier()],\n",
    "    [\"k neighbors\", KNeighborsClassifier()],\n",
    "    [\"NearestCentroid\", NearestCentroid()],\n",
    "    #[\"RadiusNeighbor\", RadiusNeighborsClassifier()],\n",
    "    [\"GaussianProcess\", GaussianProcessClassifier()],\n",
    "    [\"naive bayes Gaussian NB\", GaussianNB()],\n",
    "    [\"naive bayes Bernoulli NB\", BernoulliNB()],\n",
    "    [\"support vector machines\", SVC()],\n",
    "    [\"Nu support vector machines\", NuSVC()],\n",
    "    [\"NN MPL\", MLPClassifier()]\n",
    "]\n",
    "\n",
    "insights = []\n",
    "for modelname, model in modelclasses:\n",
    "    try:\n",
    "        model.fit(feat_train, lab_train)\n",
    "        score = model.score(feat_test, lab_test)\n",
    "        insights.append((modelname, model, score))\n",
    "    except:\n",
    "        print(modelname, \" did not work \\n\")\n",
    "\n",
    "\n",
    "insights.sort(key=lambda x: x[-1], reverse=True)\n",
    "for modelname, model, score in insights:\n",
    "    print(modelname, score)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4423fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "GBR = GradientBoostingRegressor()\n",
    "\n",
    "para_grid = [{\n",
    "    \"max_depth\" : np.linspace(1, 15, 5, dtype = int),\n",
    "    \"n_estimators\" : np.linspace(1, 200, 10, dtype = int),\n",
    "    \"learning_rate\" :  np.linspace(0.05, 2, 10).round(2)\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(GBR, para_grid, cv = 3)\n",
    "grid_search.fit(X_train, z_train)\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef48f30a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afaa8d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}