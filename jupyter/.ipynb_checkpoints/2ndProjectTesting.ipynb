{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d16ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MultiClass classifier. Predicts one attribute as one of many labels rather than just 2 possible labels.\n",
    "#This assumes there is only one right answer. We could do multilabel classification and present multiple city solutions to the user?\n",
    "#https://scikit-learn.org/stable/modules/multiclass.html    a look at different kinds of models\n",
    "# Import necessary libraries\n",
    "#     ut.run_script(re.DB_WEATHER_DESC_SCRIPT)     copy this kind of thing to add mountains/water data\n",
    "\n",
    "# method of going through multiple models\n",
    "# https://medium.com/analytics-vidhya/testing-multiple-machine-learning-models-at-once-without-getting-a-headache-5aefb0e7df03    simple good\n",
    "# https://github.com/j-planet/machine-learning-big-loop   more advanced, but better. (get parameters.py from this, and the cell for running multiple things\n",
    "\n",
    "\n",
    "# Import necessary modules from repository\n",
    "from model.data.pipeline import aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3031ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "             city  year month  temperature   humidity     pressure  \\\n0     Albuquerque  2012    10   282.594630  40.870130  1017.681818   \n1     Albuquerque  2012    11   276.787692  44.012821   994.980769   \n2     Albuquerque  2012    12   271.423110  55.940476  1010.517857   \n3     Albuquerque  2013    01   268.405723  57.488372   999.837209   \n4     Albuquerque  2013    02   271.623359  54.910256   953.775641   \n...           ...   ...   ...          ...        ...          ...   \n1666      Seattle  2017    07   286.727283  84.059140  1020.053763   \n1667      Seattle  2017    08   287.951183  84.413978  1017.043011   \n1668      Seattle  2017    09   285.830661  87.100000  1015.833333   \n1669      Seattle  2017    10   280.271667  92.629032  1019.784946   \n1670      Seattle  2017    11   279.698276  89.442529  1012.833333   \n\n      wind_speed      rain      snow     cloud       fog  extreme_weather  \n0       1.980519  0.006431  0.000000  0.456592  0.000000         0.000000  \n1       1.801282  0.019802  0.001650  0.526403  0.003300         0.003300  \n2       1.821429  0.010401  0.001486  0.754829  0.001486         0.004458  \n3       2.453488  0.036023  0.002882  0.576369  0.011527         0.001441  \n4       2.275641  0.011024  0.007874  0.587402  0.001575         0.009449  \n...          ...       ...       ...       ...       ...              ...  \n1666    1.607527  0.020161  0.000000  0.442204  0.081989         0.000000  \n1667    1.553763  0.025538  0.000000  0.302419  0.290323         0.106183  \n1668    1.738889  0.181944  0.000000  0.465278  0.226389         0.043056  \n1669    2.048387  0.231183  0.000000  0.475806  0.314516         0.002688  \n1670    3.011494  0.394548  0.010043  0.727403  0.255380         0.001435  \n\n[1671 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>year</th>\n      <th>month</th>\n      <th>temperature</th>\n      <th>humidity</th>\n      <th>pressure</th>\n      <th>wind_speed</th>\n      <th>rain</th>\n      <th>snow</th>\n      <th>cloud</th>\n      <th>fog</th>\n      <th>extreme_weather</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albuquerque</td>\n      <td>2012</td>\n      <td>10</td>\n      <td>282.594630</td>\n      <td>40.870130</td>\n      <td>1017.681818</td>\n      <td>1.980519</td>\n      <td>0.006431</td>\n      <td>0.000000</td>\n      <td>0.456592</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albuquerque</td>\n      <td>2012</td>\n      <td>11</td>\n      <td>276.787692</td>\n      <td>44.012821</td>\n      <td>994.980769</td>\n      <td>1.801282</td>\n      <td>0.019802</td>\n      <td>0.001650</td>\n      <td>0.526403</td>\n      <td>0.003300</td>\n      <td>0.003300</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albuquerque</td>\n      <td>2012</td>\n      <td>12</td>\n      <td>271.423110</td>\n      <td>55.940476</td>\n      <td>1010.517857</td>\n      <td>1.821429</td>\n      <td>0.010401</td>\n      <td>0.001486</td>\n      <td>0.754829</td>\n      <td>0.001486</td>\n      <td>0.004458</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albuquerque</td>\n      <td>2013</td>\n      <td>01</td>\n      <td>268.405723</td>\n      <td>57.488372</td>\n      <td>999.837209</td>\n      <td>2.453488</td>\n      <td>0.036023</td>\n      <td>0.002882</td>\n      <td>0.576369</td>\n      <td>0.011527</td>\n      <td>0.001441</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albuquerque</td>\n      <td>2013</td>\n      <td>02</td>\n      <td>271.623359</td>\n      <td>54.910256</td>\n      <td>953.775641</td>\n      <td>2.275641</td>\n      <td>0.011024</td>\n      <td>0.007874</td>\n      <td>0.587402</td>\n      <td>0.001575</td>\n      <td>0.009449</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1666</th>\n      <td>Seattle</td>\n      <td>2017</td>\n      <td>07</td>\n      <td>286.727283</td>\n      <td>84.059140</td>\n      <td>1020.053763</td>\n      <td>1.607527</td>\n      <td>0.020161</td>\n      <td>0.000000</td>\n      <td>0.442204</td>\n      <td>0.081989</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1667</th>\n      <td>Seattle</td>\n      <td>2017</td>\n      <td>08</td>\n      <td>287.951183</td>\n      <td>84.413978</td>\n      <td>1017.043011</td>\n      <td>1.553763</td>\n      <td>0.025538</td>\n      <td>0.000000</td>\n      <td>0.302419</td>\n      <td>0.290323</td>\n      <td>0.106183</td>\n    </tr>\n    <tr>\n      <th>1668</th>\n      <td>Seattle</td>\n      <td>2017</td>\n      <td>09</td>\n      <td>285.830661</td>\n      <td>87.100000</td>\n      <td>1015.833333</td>\n      <td>1.738889</td>\n      <td>0.181944</td>\n      <td>0.000000</td>\n      <td>0.465278</td>\n      <td>0.226389</td>\n      <td>0.043056</td>\n    </tr>\n    <tr>\n      <th>1669</th>\n      <td>Seattle</td>\n      <td>2017</td>\n      <td>10</td>\n      <td>280.271667</td>\n      <td>92.629032</td>\n      <td>1019.784946</td>\n      <td>2.048387</td>\n      <td>0.231183</td>\n      <td>0.000000</td>\n      <td>0.475806</td>\n      <td>0.314516</td>\n      <td>0.002688</td>\n    </tr>\n    <tr>\n      <th>1670</th>\n      <td>Seattle</td>\n      <td>2017</td>\n      <td>11</td>\n      <td>279.698276</td>\n      <td>89.442529</td>\n      <td>1012.833333</td>\n      <td>3.011494</td>\n      <td>0.394548</td>\n      <td>0.010043</td>\n      <td>0.727403</td>\n      <td>0.255380</td>\n      <td>0.001435</td>\n    </tr>\n  </tbody>\n</table>\n<p>1671 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = aggregate.get_agg_data_frame()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "labels = df[\"city\"]\n",
    "features = df.drop(['city','year'], axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "featPrepped = scaler.fit_transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feat_train, feat_test, lab_train, lab_test = train_test_split(featPrepped, labels, random_state = 42)\n",
    "# stratify by city for separating training and testing. stratified sampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0.3588516746411483"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(feat_train, lab_train)\n",
    "\n",
    "clf.score(feat_test,lab_test)\n",
    "# low scare shows we do not have enough destinctions between cities.\n",
    "# Score got worse when we expanded the data by years. went from like 47 % to 35 %"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4355817b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a15a761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.2822966507177033"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(feat_train, lab_train)\n",
    "\n",
    "clf.score(feat_test,lab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656fd4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bf397da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "SELECT DISTINCT weather_description\n",
    "FROM USWeather;\n",
    "\n",
    "SELECT <columns>\n",
    "FROM <table>\n",
    "#WHERE <condition>\n",
    "#ORDER BY <column> <asc/desc>;\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClf\n",
      "\n",
      "ExtraTreeClf\n",
      "\n",
      "decision tree\n",
      "\n",
      "random forest\n",
      "\n",
      "k neighbors\n",
      "\n",
      "NearestCentroid\n",
      "\n",
      "GaussianProcess\n",
      "\n",
      "naive bayes Gaussian NB\n",
      "\n",
      "naive bayes Bernoulli NB\n",
      "\n",
      "support vector machines\n",
      "\n",
      "Nu support vector machines\n",
      "\n",
      "NN MPL\n",
      "\n",
      "NN MPL 0.4019138755980861\n",
      "Nu support vector machines 0.38516746411483255\n",
      "ExtraTreeClf 0.35406698564593303\n",
      "random forest 0.35406698564593303\n",
      "GradientBoostingClf 0.35167464114832536\n",
      "support vector machines 0.3492822966507177\n",
      "GaussianProcess 0.3397129186602871\n",
      "k neighbors 0.29904306220095694\n",
      "NearestCentroid 0.2727272727272727\n",
      "decision tree 0.22248803827751196\n",
      "naive bayes Bernoulli NB 0.21770334928229665\n",
      "naive bayes Gaussian NB 0.19138755980861244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\smahe\\ai\\ml-team3\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier,  GradientBoostingClassifier\n",
    "\n",
    "\n",
    "log_reg_params = [{\"C\":0.01}, {\"C\":0.1}, {\"C\":1}, {\"C\":10}]\n",
    "dec_tree_params = [{\"criterion\": \"gini\"}, {\"criterion\": \"entropy\"}]\n",
    "rand_for_params = [{\"criterion\": \"gini\"}, {\"criterion\": \"entropy\"}]\n",
    "kneighbors_params = [{\"n_neighbors\":3}, {\"n_neighbors\":5}]\n",
    "naive_bayes_params = [{}]\n",
    "svc_params = [{\"C\":0.01}, {\"C\":0.1}, {\"C\":1}, {\"C\":10}]\n",
    "\n",
    "modelclasses = [\n",
    "    [\"GradientBoostingClf\", GradientBoostingClassifier()],\n",
    "    [\"ExtraTreeClf\", ExtraTreesClassifier()],\n",
    "    [\"decision tree\", DecisionTreeClassifier()],\n",
    "    [\"random forest\", RandomForestClassifier()],\n",
    "    [\"k neighbors\", KNeighborsClassifier()],\n",
    "    [\"NearestCentroid\", NearestCentroid()],\n",
    "    #[\"RadiusNeighbor\", RadiusNeighborsClassifier()],\n",
    "    [\"GaussianProcess\", GaussianProcessClassifier()],\n",
    "    [\"naive bayes Gaussian NB\", GaussianNB()],\n",
    "    [\"naive bayes Bernoulli NB\", BernoulliNB()],\n",
    "    [\"support vector machines\", SVC()],\n",
    "    [\"Nu support vector machines\", NuSVC()],\n",
    "    [\"NN MPL\", MLPClassifier()]\n",
    "]\n",
    "\n",
    "insights = []\n",
    "for modelname, model in modelclasses:\n",
    "    print(modelname + \"\\n\")\n",
    "    model.fit(feat_train, lab_train)\n",
    "    score = model.score(feat_test, lab_test)\n",
    "    insights.append((modelname, model, score))\n",
    "\n",
    "\n",
    "insights.sort(key=lambda x:x[-1], reverse=True)\n",
    "for modelname, model, score in insights:\n",
    "    print(modelname, score)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4423fd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef48f30a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afaa8d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}